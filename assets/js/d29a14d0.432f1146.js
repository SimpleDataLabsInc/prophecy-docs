"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[86124],{15680:(e,r,t)=>{t.d(r,{xA:()=>l,yg:()=>g});var a=t(96540);function n(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function i(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);r&&(a=a.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?i(Object(t),!0).forEach((function(r){n(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function c(e,r){if(null==e)return{};var t,a,n=function(e,r){if(null==e)return{};var t,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],r.indexOf(t)>=0||(n[t]=e[t]);return n}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var s=a.createContext({}),p=function(e){var r=a.useContext(s),t=r;return e&&(t="function"==typeof e?e(r):o(o({},r),e)),t},l=function(e){var r=p(e.components);return a.createElement(s.Provider,{value:r},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var r=e.children;return a.createElement(a.Fragment,{},r)}},b=a.forwardRef((function(e,r){var t=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),d=p(t),b=n,g=d["".concat(s,".").concat(b)]||d[b]||u[b]||i;return t?a.createElement(g,o(o({ref:r},l),{},{components:t})):a.createElement(g,o({ref:r},l))}));function g(e,r){var t=arguments,n=r&&r.mdxType;if("string"==typeof e||n){var i=t.length,o=new Array(i);o[0]=b;var c={};for(var s in r)hasOwnProperty.call(r,s)&&(c[s]=r[s]);c.originalType=e,c[d]="string"==typeof e?e:n,o[1]=c;for(var p=2;p<i;p++)o[p]=t[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}b.displayName="MDXCreateElement"},67727:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>c,toc:()=>p});var a=t(58168),n=(t(96540),t(15680));const i={title:"Prophecy Managed",id:"prophecy-managed-databricks",description:"Configuring Prophecy Managed Databricks Fabric",sidebar_position:1,tags:["deployment","configuration","google","gcp","dataproc","livy"]},o=void 0,c={unversionedId:"Spark/fabrics/prophecy-managed-databricks",id:"Spark/fabrics/prophecy-managed-databricks",title:"Prophecy Managed",description:"Configuring Prophecy Managed Databricks Fabric",source:"@site/docs/Spark/fabrics/prophecy-managed.md",sourceDirName:"Spark/fabrics",slug:"/Spark/fabrics/prophecy-managed-databricks",permalink:"/Spark/fabrics/prophecy-managed-databricks",draft:!1,tags:[{label:"deployment",permalink:"/tags/deployment"},{label:"configuration",permalink:"/tags/configuration"},{label:"google",permalink:"/tags/google"},{label:"gcp",permalink:"/tags/gcp"},{label:"dataproc",permalink:"/tags/dataproc"},{label:"livy",permalink:"/tags/livy"}],version:"current",sidebarPosition:1,frontMatter:{title:"Prophecy Managed",id:"prophecy-managed-databricks",description:"Configuring Prophecy Managed Databricks Fabric",sidebar_position:1,tags:["deployment","configuration","google","gcp","dataproc","livy"]},sidebar:"defaultSidebar",previous:{title:"Prophecy Fabrics",permalink:"/Spark/fabrics/"},next:{title:"Databricks",permalink:"/Spark/fabrics/databricks-fabric"}},s={},p=[],l={toc:p},d="wrapper";function u(e){let{components:r,...t}=e;return(0,n.yg)(d,(0,a.A)({},l,t,{components:r,mdxType:"MDXLayout"}),(0,n.yg)("p",null,"If you don't have a Databricks environment, use the Prophecy Managed Databricks Fabric to get started.\nUsing this option, you can create a 14-Day Free Trial Fabric using Prophecy Managed Databricks. You can use this when trying out Prophecy and when you don't want to connect your own Spark Execution Environment to Prophecy. We already have some sample data and tables created to try out the different functionalities.\nPlease refer to the video below for a step-by-step example"),(0,n.yg)("div",{class:"wistia_responsive_padding",style:{padding:"56.25% 0 0 0",position:"relative"}},(0,n.yg)("div",{class:"wistia_responsive_wrapper",style:{height:"100%",left:0,position:"absolute",top:0,width:"100%"}},(0,n.yg)("iframe",{src:"https://user-images.githubusercontent.com/121796483/217787623-1cf01df2-54d6-4338-bd59-bd921e101ce9.mp4",title:"Databricks Fabric",allow:"autoplay;fullscreen",allowtransparency:"true",frameborder:"0",scrolling:"no",class:"wistia_embed",name:"wistia_embed",msallowfullscreen:!0,width:"100%",height:"100%"}))),(0,n.yg)("p",null,"In this Fabric you can only change the ",(0,n.yg)("a",{parentName:"p",href:"https://docs.databricks.com/runtime/dbr.html#databricks-runtime"},"Databricks Runtime version"),". The auto-termination timeout, Executor and Driver Machine Type and Job sizes are uneditable."))}u.isMDXComponent=!0}}]);