"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[4510],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>m});var r=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var c=r.createContext({}),l=function(e){var t=r.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=l(e.components);return r.createElement(c.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=l(a),h=n,m=u["".concat(c,".").concat(h)]||u[h]||d[h]||o;return a?r.createElement(m,i(i({ref:t},p),{},{components:a})):r.createElement(m,i({ref:t},p))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=h;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[u]="string"==typeof e?e:n,i[1]=s;for(var l=2;l<o;l++)i[l]=a[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}h.displayName="MDXCreateElement"},80846:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var r=a(87462),n=(a(67294),a(3905));const o={title:"Deployment",date:new Date("2022-03-21T21:45:41.000Z"),sidebar_position:1,id:"deployment",description:"Prophecy deployment is flexible and supports multiple mechanisms",tags:["deployment","jobs","databricks"]},i=void 0,s={unversionedId:"architecture/deployment/deployment",id:"architecture/deployment/deployment",title:"Deployment",description:"Prophecy deployment is flexible and supports multiple mechanisms",source:"@site/docs/architecture/deployment/deployment.md",sourceDirName:"architecture/deployment",slug:"/architecture/deployment/",permalink:"/architecture/deployment/",draft:!1,tags:[{label:"deployment",permalink:"/tags/deployment"},{label:"jobs",permalink:"/tags/jobs"},{label:"databricks",permalink:"/tags/databricks"}],version:"current",sidebarPosition:1,frontMatter:{title:"Deployment",date:"2022-03-21T21:45:41.000Z",sidebar_position:1,id:"deployment",description:"Prophecy deployment is flexible and supports multiple mechanisms",tags:["deployment","jobs","databricks"]},sidebar:"defaultSidebar",previous:{title:"SAML Using Okta",permalink:"/architecture/authentication/saml_okta"},next:{title:"On premise",permalink:"/architecture/deployment/on-premise"}},c={},l=[{value:"Cloud Deployment",id:"cloud-deployment",level:2},{value:"Public SaaS",id:"public-saas",level:3},{value:"Private SaaS (Customer VPC)",id:"private-saas-customer-vpc",level:3},{value:"On-Premise Deployment",id:"on-premise-deployment",level:3},{value:"Connectivity",id:"connectivity",level:2},{value:"Spark",id:"spark",level:3},{value:"Databricks",id:"databricks",level:4},{value:"Git",id:"git",level:3}],p={toc:l},u="wrapper";function d(e){let{components:t,...o}=e;return(0,n.kt)(u,(0,r.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"Prophecy deployment is simple and flexible. Prophecy is written as a set of microservices that run on Kubernetes and is built to be multi-tenant. There are three primary options:"),(0,n.kt)("h2",{id:"cloud-deployment"},"Cloud Deployment"),(0,n.kt)("p",null,"Prophecy in the cloud connects to your existing Spark and Scheduler/Orchestrator. Prophecy does not store any data, however, it does store metadata about your Pipelines, Datasets and schedules."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"General architecture",src:a(76652).Z,width:"1520",height:"736"})),(0,n.kt)("h3",{id:"public-saas"},"Public SaaS"),(0,n.kt)("p",null,"Public SaaS (Prophecy managed SaaS) is the default option when you connect from ",(0,n.kt)("strong",{parentName:"p"},"Databricks Partner Connect")," and is free for one user.\nThis option is heavily used by customers to try Prophecy. Our startup and midsize customers who like the convenience of a managed service prefer this option. You can also use this by directly going to the ",(0,n.kt)("a",{parentName:"p",href:"https://app.prophecy.io/"},"Prophecy Application"),"."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"VPC Architecture",src:a(6516).Z,width:"1560",height:"774"})),(0,n.kt)("h3",{id:"private-saas-customer-vpc"},"Private SaaS (Customer VPC)"),(0,n.kt)("p",null,"Our Enterprise customers and midsize/startup customers in segments which deal with very sensitive data primarily use this option. Here, Prophecy runs within the ",(0,n.kt)("strong",{parentName:"p"},"Customer VPC")," and connects to the identity, Spark clusters and the scheduler within the VPC."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Customer VPC Architecure",src:a(26309).Z,width:"1560",height:"774"})),(0,n.kt)("p",null,"This is the default option when you go through the cloud marketplaces. You can install the software from the ",(0,n.kt)("a",{parentName:"p",href:"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/simpledatalabsinc1635791235920.prophecy-data-engineering"},"Azure Marketplace"),". The install is very simple, takes about 20 minutes (with confirmation popup), and billing starts after 30 days."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Azure Architecture",src:a(35004).Z,width:"3574",height:"1530"})),(0,n.kt)("h3",{id:"on-premise-deployment"},"On-Premise Deployment"),(0,n.kt)("p",null,"On rare occasions Prophecy will deploy on-premise for the large customers who are moving to the cloud. Often the order is that the organizations will move Pipelines from on-premise legacy ETL tools to Spark, then move it to Spark on the cloud. For more information read the ",(0,n.kt)("a",{parentName:"p",href:"/architecture/deployment/on-premise"},"on-premise installation documentation")," or reach out to our team by using ",(0,n.kt)("a",{parentName:"p",href:"https://www.prophecy.io/request-a-demo"},"request a demo"),"."),(0,n.kt)("h2",{id:"connectivity"},"Connectivity"),(0,n.kt)("p",null,"Prophecy connects to the following external services:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"#spark"},"Spark")," - for interactive code execution"),(0,n.kt)("li",{parentName:"ul"},"Schedulers - for code orchestration"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"#git"},"Git")," - for code storage"),(0,n.kt)("li",{parentName:"ul"},"Identity Providers - for easier user authentication and authorization")),(0,n.kt)("h3",{id:"spark"},"Spark"),(0,n.kt)("p",null,"To allow for interactive code execution Prophecy can connect to either ",(0,n.kt)("a",{parentName:"p",href:"#databricks"},"Databricks")," or any other Spark through ",(0,n.kt)("a",{parentName:"p",href:"https://livy.apache.org/"},"Apache Livy")," (e.g. MapR, CDP, HDP, Spark on Kubernetes)."),(0,n.kt)("h4",{id:"databricks"},"Databricks"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Prophecy &lt;&gt; Databricks Connectivity",src:a(18510).Z,width:"3314",height:"1580"})),(0,n.kt)("p",null,"Prophecy connects to Databricks using ",(0,n.kt)("a",{parentName:"p",href:"https://docs.databricks.com/dev-tools/api/latest/index.html"},"Rest API"),". Each ",(0,n.kt)("a",{parentName:"p",href:"../../concepts/fabrics"},"Fabric")," defined in Prophecy refers to a single ",(0,n.kt)("a",{parentName:"p",href:"https://docs.databricks.com/workspace/index.html"},"Databricks workspace")," and each user is required to provide a ",(0,n.kt)("a",{parentName:"p",href:"https://docs.databricks.com/dev-tools/api/latest/authentication.html"},"personal access token")," to authenticate to it."),(0,n.kt)("p",null,"Security-conscious enterprises that use Databricks with limited network access have to additionally add the ",(0,n.kt)("strong",{parentName:"p"},"Prophecy Data Plane IP address")," (",(0,n.kt)("inlineCode",{parentName:"p"},"3.133.35.237"),") to the Databricks allowed ",(0,n.kt)("a",{parentName:"p",href:"https://docs.databricks.com/security/network/ip-access-list.html#add-an-ip-access-list"},"access list"),"."),(0,n.kt)("p",null,"Primarily Prophecy uses Databricks for the following functionalities:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Interactive Execution")," - Prophecy allows its users to spin up new clusters or connect to existing clusters. When a cluster connection exists, Prophecy allows the user to run their code in the interactive mode. Interactive code queries are sent to Databricks using the ",(0,n.kt)("a",{parentName:"li",href:"https://docs.databricks.com/dev-tools/api/1.2/index.html"},"Databricks Command API 1.2"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Scheduling")," - Prophecy allows the user to build and orchestrate Databricks Jobs. This works through the ",(0,n.kt)("a",{parentName:"li",href:"https://docs.databricks.com/dev-tools/api/latest/jobs.html"},"Databricks Jobs API 2.1"),".")),(0,n.kt)("p",null,"By default, Prophecy does not store any data samples when executing code using Databricks. Data samples can be optionally stored for observability purposes (execution metrics)."),(0,n.kt)("admonition",{type:"note"},(0,n.kt)("p",{parentName:"admonition"},"When using ",(0,n.kt)("strong",{parentName:"p"},"Active Directory"),", Prophecy takes care of auto-generation and refreshing of the Databricks personal access tokens. Read more about it ",(0,n.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/aad/"},"here"),".")),(0,n.kt)("h3",{id:"git"},"Git"),(0,n.kt)("p",null,"Supported Git providers:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Prophecy Managed")," - Prophecy automatically sets up the connectivity between itself and the repositories. Prophecy Managed is based on open-source ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/go-gitea/gitea"},"GitTea"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"GitHub")," (including GitHub Enterprise) - authenticates using per-user personal access tokens. ",(0,n.kt)("a",{parentName:"li",href:"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token"},"How to generate PAT?")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Bitbucket")," (including Bitbucket self-hosted) - authenticates using per-user personal access tokens. ",(0,n.kt)("a",{parentName:"li",href:"https://confluence.atlassian.com/bitbucketserver072/personal-access-tokens-1005335924.html"},"How to generate PAT?")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"GitLab")," (including GitLab self-hosted) - authenticates using per-user personal access tokens. ",(0,n.kt)("a",{parentName:"li",href:"https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html"},"How to generate PAT?")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Azure DevOps")," - authenticates using per-user personal access tokens. ",(0,n.kt)("a",{parentName:"li",href:"https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops&tabs=Windows"},"How to generate PAT?"))),(0,n.kt)("p",null,"Security-conscious enterprises that use Git Providers within private networks behind firewalls have to add the Prophecy Control Plane IP address (",(0,n.kt)("inlineCode",{parentName:"p"},"3.133.35.237"),") to the private network allow-list or to the Git provider ",(0,n.kt)("a",{parentName:"p",href:"https://github.blog/2019-12-12-ip-allow-lists-now-in-public-beta/"},"allow-list"),"."),(0,n.kt)("admonition",{type:"info"},(0,n.kt)("p",{parentName:"admonition"},(0,n.kt)("strong",{parentName:"p"},"Coming Soon"),"\nUsers will be able to connect to common Git providers, by leveraging their respective OAuth functionalities. E.g. ",(0,n.kt)("a",{parentName:"p",href:"https://docs.github.com/en/developers/apps/building-oauth-apps/authorizing-oauth-apps"},"GitHub OAuth")," or Azure AD.")))}d.isMDXComponent=!0},26309:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/arch_customervpc-9606898420e67c54bfda2880228e6f3a.png"},76652:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/arch_general-32c8841bc2ae1f4053f6662018a756d9.png"},6516:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/arch_separate_vpc-0fd8afc057178ba04bf50999084516ea.png"},18510:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/connectivity-databricks-2e75fbad06dbbcac1dc08355dfc0d0fc.png"},35004:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/prophecy_azure-1b6d764b1d555da3ca7b2d02604b3e75.png"}}]);