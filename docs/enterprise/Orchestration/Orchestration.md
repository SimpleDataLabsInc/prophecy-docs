---
title: Orchestration
id: Orchestration
slug: /engineers/orchestration
description: Schedule pipeline execution with jobs
tags:
  - jobs
  - deployment
  - scheduling
---

Once you have developed a Spark data pipeline or an SQL model using Prophecy, you may want to schedule it to run at some regular frequency. To support this, Prophecy provides you with an easy-to-use interface to develop jobs that run on external schedulers.

- [Databricks Jobs](databricks-jobs.md).
- Apache Airflow DAGs
- [Custom](alternative-schedulers.md)

## What's next

To continue exploring orchestration solutions, see the following pages:

```mdx-code-block
import DocCardList from '@theme/DocCardList';
import {useCurrentSidebarCategory} from '@docusaurus/theme-common';

<DocCardList items={useCurrentSidebarCategory().items}/>
```
