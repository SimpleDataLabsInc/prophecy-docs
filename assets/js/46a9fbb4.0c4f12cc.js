"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[2113],{15680:(e,r,t)=>{t.d(r,{xA:()=>g,yg:()=>d});var a=t(96540);function n(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function i(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);r&&(a=a.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?i(Object(t),!0).forEach((function(r){n(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function s(e,r){if(null==e)return{};var t,a,n=function(e,r){if(null==e)return{};var t,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],r.indexOf(t)>=0||(n[t]=e[t]);return n}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var p=a.createContext({}),l=function(e){var r=a.useContext(p),t=r;return e&&(t="function"==typeof e?e(r):o(o({},r),e)),t},g=function(e){var r=l(e.components);return a.createElement(p.Provider,{value:r},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var r=e.children;return a.createElement(a.Fragment,{},r)}},u=a.forwardRef((function(e,r){var t=e.components,n=e.mdxType,i=e.originalType,p=e.parentName,g=s(e,["components","mdxType","originalType","parentName"]),c=l(t),u=n,d=c["".concat(p,".").concat(u)]||c[u]||m[u]||i;return t?a.createElement(d,o(o({ref:r},g),{},{components:t})):a.createElement(d,o({ref:r},g))}));function d(e,r){var t=arguments,n=r&&r.mdxType;if("string"==typeof e||n){var i=t.length,o=new Array(i);o[0]=u;var s={};for(var p in r)hasOwnProperty.call(r,p)&&(s[p]=r[p]);s.originalType=e,s[c]="string"==typeof e?e:n,o[1]=s;for(var l=2;l<i;l++)o[l]=t[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},33899:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var a=t(58168),n=(t(96540),t(15680));const i={title:"Spark Structured Streaming",id:"streaming",description:"Prophecy Streaming Gems",tags:["streaming","gems","source","target"]},o=void 0,s={unversionedId:"Spark/spark-streaming/streaming",id:"Spark/spark-streaming/streaming",title:"Spark Structured Streaming",description:"Prophecy Streaming Gems",source:"@site/docs/Spark/spark-streaming/spark-streaming.md",sourceDirName:"Spark/spark-streaming",slug:"/Spark/spark-streaming/",permalink:"/Spark/spark-streaming/",draft:!1,tags:[{label:"streaming",permalink:"/tags/streaming"},{label:"gems",permalink:"/tags/gems"},{label:"source",permalink:"/tags/source"},{label:"target",permalink:"/tags/target"}],version:"current",frontMatter:{title:"Spark Structured Streaming",id:"streaming",description:"Prophecy Streaming Gems",tags:["streaming","gems","source","target"]},sidebar:"defaultSidebar",previous:{title:"Gem builder",permalink:"/Spark/extensibility/gem-builder"},next:{title:"Streaming Sources and Targets",permalink:"/Spark/spark-streaming/streaming-sources-and-targets/"}},p={},l=[{value:"Spark Structured Streaming using Prophecy IDE",id:"spark-structured-streaming-using-prophecy-ide",level:2},{value:"Working with a Streaming Pipeline",id:"working-with-a-streaming-pipeline",level:3},{value:"Streaming Sources and Targets",id:"streaming-sources-and-targets",level:3},{value:"Streaming Transformations",id:"streaming-transformations",level:3}],g={toc:l},c="wrapper";function m(e){let{components:r,...i}=e;return(0,n.yg)(c,(0,a.A)({},g,i,{components:r,mdxType:"MDXLayout"}),(0,n.yg)("p",null,"Prophecy 2.7 introduces native support for streaming data running on Spark Structured Streaming. The streaming capability is available for ",(0,n.yg)("inlineCode",{parentName:"p"},"Python")," projects. Support for Scala will be added in the future."),(0,n.yg)("p",null,"Streaming pipelines work differently from batch pipelines:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Streaming applications are always running, continuously processing incoming data."),(0,n.yg)("li",{parentName:"ol"},"Data is processed in micro-batches, with the notable exception of ",(0,n.yg)("a",{parentName:"li",href:"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#continuous-processing"},"Continuous Triggers")," (an experimental feature available in Spark3.3). Continuous triggers are not supported by Prophecy."),(0,n.yg)("li",{parentName:"ol"},"Streaming applications handle transient data rather than maintain the entire data. Aggregations and joins require watermarking for maintaining a limited state."),(0,n.yg)("li",{parentName:"ol"},"All Streaming Datasets can behave similarly to Batch datasets using the Spark ",(0,n.yg)("inlineCode",{parentName:"li"},"ForEachBatch"),". More on ",(0,n.yg)("inlineCode",{parentName:"li"},"ForEachBatch")," ",(0,n.yg)("a",{parentName:"li",href:"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.streaming.DataStreamWriter.foreachBatch.html"},"here")," Note that ",(0,n.yg)("inlineCode",{parentName:"li"},"forEachBatch")," is not supported by Prophecy.")),(0,n.yg)("p",null,"This documentation assumes you are already familiar with how Structured Streaming works. For more information, you can consult the Structured Streaming documentation ",(0,n.yg)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html"},"here"),"."),(0,n.yg)("h2",{id:"spark-structured-streaming-using-prophecy-ide"},"Spark Structured Streaming using Prophecy IDE"),(0,n.yg)("p",null,(0,n.yg)("img",{alt:"How to Create a Streaming Pipeline",src:t(1335).A,width:"1816",height:"1270"}),"\nWithin a Prophecy ",(0,n.yg)("inlineCode",{parentName:"p"},"Python")," Project, a user can create a Structured Streaming Pipeline using the Streaming(beta) mode."),(0,n.yg)("h3",{id:"working-with-a-streaming-pipeline"},"Working with a Streaming Pipeline"),(0,n.yg)("p",null,"To create a Streaming Pipeline, users can follow a process similar to creating a Batch Pipeline in a ",(0,n.yg)("inlineCode",{parentName:"p"},"Python")," project. For more on Pipeline creation and understanding Prophecy pipelines, please check ",(0,n.yg)("a",{parentName:"p",href:"/concepts/project/pipeline"},"this")," link. Streaming Pipelines work differently from Batch Pipelines in the following ways:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Partial runs are not supported for streaming applications. A partial run is only allowed on a ",(0,n.yg)("inlineCode",{parentName:"li"},"Streaming Target")," Gem."),(0,n.yg)("li",{parentName:"ol"},"Streaming pipelines are long-running tasks and process data at intervals. Currently, they do not capture cumulative statistics."),(0,n.yg)("li",{parentName:"ol"},'Streaming Pipelines are continuous and do not stop running. To terminate a Streaming Pipeline, users need to click the "X" button. A Streaming Pipeline is an ongoing process and will not terminate itself.'),(0,n.yg)("li",{parentName:"ol"},"To deploy the Pipeline on Databricks, users can follow the same process described ",(0,n.yg)("a",{parentName:"li",href:"/Orchestration/databricks-jobs"},"here"),". A scheduled Job will check if the Streaming Pipeline is running every X minutes. If the Pipeline is not running, the Job will attempt to start it.")),(0,n.yg)("h3",{id:"streaming-sources-and-targets"},"Streaming Sources and Targets"),(0,n.yg)("p",null,"Spark Structured Streaming applications have a variety of source and target components available to construct Piplines."),(0,n.yg)("p",null,"Streaming source gems render to ",(0,n.yg)("inlineCode",{parentName:"p"},"spark.readStream()")," on the Spark side. Currently, we support file stream-based sources and targets, warehouse-based targets, and event stream-based sources and targets. For more information on Streaming Source and Target Gems, click ",(0,n.yg)("a",{parentName:"p",href:"/Spark/spark-streaming/streaming-sources-and-targets/"},"here"),"."),(0,n.yg)("p",null,"Additionally, any batch data sources can be used in a streaming application. Batch data sources are read using the ",(0,n.yg)("inlineCode",{parentName:"p"},"spark.read()")," function at every processing trigger (due to Spark evaluating lazily). More on triggers ",(0,n.yg)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#triggers"},"here"),". For more information on Batch Source and Target Gems, click ",(0,n.yg)("a",{parentName:"p",href:"/Spark/gems/source-target/"},"here"),"."),(0,n.yg)("h3",{id:"streaming-transformations"},"Streaming Transformations"),(0,n.yg)("p",null,"For more information on Streaming Transformations, click ",(0,n.yg)("a",{parentName:"p",href:"/Spark/spark-streaming/transformations-streaming"},"here"),"."))}m.isMDXComponent=!0},1335:(e,r,t)=>{t.d(r,{A:()=>a});const a=t.p+"assets/images/create-streaming-pipeline-09c38e5fc7c91853e19a517c3024c518.png"}}]);