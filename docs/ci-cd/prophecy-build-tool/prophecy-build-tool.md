---
title: Prophecy Build Tool (PBT)
id: prophecy-build-tool
slug: /engineers/prophecy-build-tool
description: Prophecy Build tool
tags:
  - metadata
  - build
  - deploy
  - test
  - cli
  - continuous integration
  - continuous deployment
---

:::edition Enterprise
Available for [Enterprise Edition](/getting-started/editions/) only.
:::

The **Prophecy-build-tool** (PBT) allows you to build, test and deploy projects generated by Prophecy from the command line. This lets you integrate Prophecy projectsd with your own CI/CD (such as GitHub Actions), build system (such as Jenkins), and
orchestration (such as Databricks Workflows).

## Features (v1.1.0)

- Build pipelines (all or specify ones to build) in Prophecy projects (Scala and Python)
- Unit test pipelines in Prophecy projects (Scala and Python)
- Deploy jobs with built pipelines on Databricks
- Deploying jobs filtered with fabric ids on Databricks
- Integrate with CI/CD tools like GitHub Actions
- Verify the project structure of Prophecy projects
- Deploying pipeline Configurations

## Requirements

- Python >=3.7 (Recommended 3.9.13)
- pip
- `pyspark` (Recommended 3.3.0)

## Installation

To install PBT, run:

```
pip3 install prophecy-build-tool
```

## Integration examples

[GitHub Actions](pbt-github-actions.md)

[Jenkins](pbt-jenkins.md)

## Usage

```shell
Usage: pbt [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  build
  deploy
  test
```

## Running PBT

The PBT client can be used to build, test and deploy projects created by Prophecy that are present in your local filesystem.

Please make sure the **DATABRICKS_URL** and **DATABRICKS_TOKEN** environment variables are set appropriately pointing to your Databricks workspace before running any PBT commands.

Example:

```shell
export DATABRICKS_HOST="https://example_databricks_host.cloud.databricks.com"
export DATABRICKS_TOKEN="exampledatabrickstoken"
```

## Build pipelines and deploy jobs

PBT can build and deploy jobs inside your Prophecy project to the Databricks environment defined by the `DATABRICKS_HOST` and `DATABRICKS_TOKEN`
environment variables.

Since v1.0.3 PBT supports new input parameters that are used to determine the DBFS path where your project's artifacts would
be uploaded. These are the `--release-version` and `--project-id` parameters which would be used to replace the `__PROJECT_RELEASE_VERSION_ PLACEHOLDER__` and `__PROJECT_ID_PLACEHOLDER__` placeholders that would already be present in your job's definition file
(`databricks-job.json`). Using a unique release version of your choice and the project's Prophecy ID
(as seen in the project's URL on the Prophecy UI) is recommended.

### Build

The `build` command builds all projects.

```shell
pbt build --path /path/to/your/prophecy_project/
```

#### Build options

| Option                  | Description                                                                                              |
| ----------------------- | -------------------------------------------------------------------------------------------------------- |
| `--path TEXT`           | Path to the directory containing the `pbt_project.yml` file **[required]**                               |
| `--pipelines TEXT`      | Pipeline names (comma separated) used to filter pipelines to be built                                    |
| `--ignore-build-errors` | Ignores any build errors in pipelines and returns success (`EXIT_CODE = 0`); refer to logs for details   |
| `--ignore-parse-errors` | Ignores any parsing errors in pipelines and returns success (`EXIT_CODE = 0`); refer to logs for details |
| `--help`                | Show this message and exit                                                                               |

If your project has a large number of pipelines, you can specify pipelines to be built using the `--pipelines` command. To specify multiple pipelines, separtate these with commas.

Usage:

```shell
pbt build --pipelines customers_orders,join_agg_sort  --path /path/to/your/prophecy_project/
```

PBT builds fail (with `EXIT 1`) if any pipeline builds fail (as a result of a corrupt pipeline, for example).

To continue, you can skip these errors by using the following flags:

| Flag                    | Description                          |
| ----------------------- | ------------------------------------ |
| `--ignore-build-errors` | Skips package build failures         |
| `--ignore-parse-errors` | Skips project parsing error failures |

Usage:

```shell
pbt build --path /path/to/your/prophecy_project/ --ignore-build-errors --ignore-parse-errors
```

### Deploy

The `deploy` command builds all pipelines and deploys all projects.

Usage:

```shell
pbt deploy --path /path/to/your/prophecy_project/ --release-version 1.0 --project-id 10
```

Sample output:

```shell
Prophecy-build-tool v1.0.4.1

Found 1 jobs: daily
Found 1 pipelines: customers_orders (python)

Building 1 pipelines üö∞

  Building pipeline pipelines/customers_orders [1/1]

‚úÖ Build complete!

Deploying 1 jobs ‚è±

  Deploying job jobs/daily [1/1]
    Uploading customers_orders-1.0-py3-none-any.whl to
dbfs:/FileStore/prophecy/artifacts/...
Querying existing jobs to find current job: Offset: 0, Pagesize: 25
    Updating an existing job: daily

‚úÖ Deployment completed successfully!
```

#### Specify dependent projects

You can specify dependent projects by using the `--dependent-projects-path` command.

This can be useful if you have dependent pipelines whose source code can be cloned into a different directory accessible to PBT while running `deploy` for the main project. This option supports only one path as argument, but the path itself can contain multiple Prophecy projects within it in different subdirectories.

Usage:

```shell
pbt deploy --path /path/to/your/prophecy_project/ --release-version 1.0 --project-id 10 --dependent-projects-path /path/to/dependent/prophecy/projects
```

#### Specify fabric IDs

You can also specify fabrics by using the `--fabric-ids` flag. This option can be useful in a multi-workspace environment.
[Find the Fabric ID](pbt-jenkins.md) for your fabric by navigating to the Metadata page of that fabric and observing the URL.

The following command will filter out and only deploy the jobs associated with given Fabric IDs.

Usage:

```shell
pbt deploy --fabric-ids 647,1527 --path /path/to/your/prophecy_project/
```

Sample output:

```shell
Project name: HelloWorld
Found 2 jobs: ashish-TestJob2, ashish-TestJob
Found 4 pipelines: customers_orders (python), report_top_customers (python), join_agg_sort (python),
farmers-markets-irs (python)
[SKIP]: Skipping builds for all pipelines as '--skip-builds' flag is passed.

 Deploying 2 jobs
Deploying jobs only for given Fabric IDs: ['647', '1527']

[START]:  Deploying job jobs/TestJob2 [1/2]
[DEPLOY]: Job being deployed for fabric id: 1527
    Pipeline pipelines/farmers-markets-irs might be shared, checking if it exists in DBFS
    Dependent package exists on DBFS already, continuing with next pipeline
    Pipeline pipelines/report_top_customers might be shared, checking if it exists in DBFS
    Dependent package exists on DBFS already, continuing with next pipeline
    Querying existing jobs to find current job: Offset: 0, Pagesize: 25
    Updating an existing job: ashish-TestJob2

[START]:  Deploying job jobs/TestJob [2/2]
[DEPLOY]: Job being deployed for fabric id: 647
    Pipeline pipelines/customers_orders might be shared, checking if it exists in DBFS
    Dependent package exists on DBFS already, continuing with next pipeline
    Pipeline pipelines/join_agg_sort might be shared, checking if it exists in DBFS
    Dependent package exists on DBFS already, continuing with next pipeline
    Pipeline pipelines/report_top_customers might be shared, checking if it exists in DBFS
    Dependent package exists on DBFS already, continuing with next pipeline
    Querying existing jobs to find current job: Offset: 0, Pagesize: 25
    Updating an existing job: ashish-TestJob

‚úÖ Deployment completed successfully!
```

By default, `deploy` command builds all pipelines and then deploys them, if you want to skip building all pipelines
( this could be useful, if you are running a `deploy` command after running `deploy` or `build` previously.)

```shell
pbt deploy --skip-builds --path /path/to/your/prophecy_project/
```

#### Specify jobs

By default, the `deploy` command builds all pipelines and deploys all jobs.

To deploy specific jobs, use the `job-ids` filter (To find a job's JobId, view the Jobs metadata page).

PBT will automatically calculate all the pipelines needed for the jobs and then build them.

This option is especially useful for projects with many jobs.

Usage:

```shell
pbt deploy --path /path/to/your/prophecy_project/ --job-ids "TestJob1"
```

You can also pass multiple Job Ids separated by commas:

```shell
pbt deploy --path /path/to/your/prophecy_project/ --job-ids "TestJob1,TestJob2"
```

#### Deploy options

Usage:

`pbt deploy [OPTIONS]`

| Option                           | Description                                                                    |
| -------------------------------- | ------------------------------------------------------------------------------ |
| `--path TEXT`                    | **Required** Path to the directory containing the `pbt_project.yml` file.      |
| `--dependent-projects-path TEXT` | Dependent projects path.                                                       |
| `--release-version TEXT`         | Release version to be used during deployments.                                 |
| `--project-id TEXT`              | Project ID placeholder to be used during deployments.                          |
| `--prophecy-url TEXT`            | Prophecy URL placeholder to be used during deployments.                        |
| `--fabric-ids TEXT`              | Fabric IDs (comma separated) which can be used to filter jobs for deployments. |
| `--skip-builds`                  | Flag to skip building Pipelines.                                               |
| `--help`                         | Show this message and exit.                                                    |

### Test

PBT supports running unit tests inside the Prophecy project.

Unit tests run with the `default` configuration present in the Pipeline's `configs/resources/config` directory.

#### Test options

| Option                  | Description                                                                 |
| ----------------------- | --------------------------------------------------------------------------- |
| `--path`                | Path to the directory containing the `pbt_project.yml` file **[required]**. |
| `--driver-library-path` | JAR path of `prophecy-python-libs` and other required dependencies          |
| `--pipelines`           | Pipeline names (comma separated) used to filter pipelines to be tested.     |
| `--help`                | Show this message and exit.                                                 |

To run all unit tests present in the project, use the `test` command as follows:

```shell
pbt test --path /path/to/your/prophecy_project/
```

Sample output:

```shell
Prophecy-build-tool v1.0.1

Found 1 jobs: daily
Found 1 pipelines: customers_orders (python)

  Unit Testing pipeline pipelines/customers_orders [1/1]

    ============================= test session starts ==============================
    platform darwin -- Python 3.8.9, pytest-7.1.2, pluggy-1.0.0 -- /Library/Developer/CommandLineTools/usr/bin/python
    cachedir: .pytest_cache
    metadata: None
    rootdir: /path/to/your/prophecy_project/pipelines/customers_orders/code
    plugins: html-3.1.1, metadata-2.0.2
    collecting ... collected 1 item

    test/TestSuite.py::CleanupTest::test_unit_test_0 PASSED                  [100%]

    ============================== 1 passed in 17.42s ==============================

‚úÖ Unit test for pipeline: pipelines/customers_orders succeeded.
```

You can also pass `--driver-library-path` as a parameter to the `pbt test` command to pass jars of Prophecy-libs dependencies to the command. If user doesn't add it, the tool by default picks the libraries from maven central.

```shell
pbt test --path /path/to/your/prophecy_project/ --driver-library-path <path_to_the_jars>
```

### Validate

PBT supports validating all pipelines inside the Prophecy project. This lets you check pipelines before deploying.

Validation involves checking if the pipelines have any diagnostics. These are the same diagnostics which are shown in Prophecy's Visual IDE.

To run validate for all pipelines present in the project, use the `validate` command as follows:

```shell
pbt validate --path /path/to/your/prophecy_project/
```

#### Validate options

| Option                       | Description                                                                |
| ---------------------------- | -------------------------------------------------------------------------- |
| `--path TEXT`                | Path to the directory containing the `pbt_project.yml` file **[required]** |
| `--treat-warnings-as-errors` | Specifies whether to treat warnings as errors.                             |
| `--help`                     | Show this message and exit.                                                |

Sample output:

```shell
Prophecy-build-tool v1.0.3.4

Project name: HelloWorld
Found 1 jobs: default_schedule
Found 4 pipelines: customers_orders (python), report_top_customers (python), join_agg_sort (python), farmers-markets-irs (python)

Validating 4 pipelines

  Validating pipeline pipelines/customers_orders [1/4]

 Pipeline is validated: customers_orders

  Validating pipeline pipelines/report_top_customers [2/4]

 Pipeline is validated: report_top_customers

  Validating pipeline pipelines/join_agg_sort [3/4]

 Pipeline is validated: join_agg_sort

  Validating pipeline pipelines/farmers-markets-irs [4/4]

 Pipeline is validated: farmers-markets-irs
```

## What's next

To continue using PBT, see the following pages:

```mdx-code-block
import DocCardList from '@theme/DocCardList';
import {useCurrentSidebarCategory} from '@docusaurus/theme-common';

<DocCardList items={useCurrentSidebarCategory().items}/>
```
