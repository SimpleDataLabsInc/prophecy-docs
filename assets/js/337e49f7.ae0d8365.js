"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[50369],{28066:i=>{i.exports=JSON.parse('{"tag":{"label":"databricks","permalink":"/tags/databricks","allTagsPath":"/tags","count":13,"items":[{"id":"administration/fabrics/Spark-fabrics/databricks/whitelist-plibs","title":"Add Prophecy libraries to allowlist for UC standard clusters","description":"Make ProphecyLibs available to Databricks UC standard clusters","permalink":"/admin/dbx-whitelist-plibs"},{"id":"administration/fabrics/Spark-fabrics/databricks/databricks","title":"Databricks","description":"Connect Prophecy to your existing Databricks workspace","permalink":"/administration/fabrics/Spark-fabrics/databricks/"},{"id":"administration/fabrics/prophecy-fabrics/connections/databricks","title":"Databricks connection","description":"Learn how to connect with Databricks","permalink":"/administration/fabrics/prophecy-fabrics/connections/databricks"},{"id":"administration/authentication/databricks-oauth","title":"Databricks OAuth","description":"Prophecy Databricks OAuth integration","permalink":"/databricks-oauth-authentication"},{"id":"getting-started/quick-starts/databricks-partner-connect","title":"Databricks Partner Connect","description":"Get started with Prophecy via Databricks Partner Connect","permalink":"/databricks-partner-connect"},{"id":"administration/fabrics/Spark-fabrics/databricks/databricks-policies","title":"Databricks policies","description":"Review the impact of Databricks policies in Prophecy","permalink":"/administration/fabrics/Spark-fabrics/databricks/databricks-policies"},{"id":"administration/fabrics/Spark-fabrics/databricks/databricks-serverless","title":"Databricks serverless compute for PySpark","description":"Use Databricks serverless compute to execute PySpark pipelines","permalink":"/administration/fabrics/Spark-fabrics/databricks/databricks-serverless"},{"id":"administration/fabrics/sql-fabrics/databricks","title":"Databricks SQL","description":"Run models on a Databricks SQL warehouse","permalink":"/administration/fabrics/sql-fabrics/databricks"},{"id":"analysts/development/models/target-platforms/databricks-target","title":"Databricks targets","description":"Configure target models for Databricks SQL","permalink":"/engineers/databricks-target"},{"id":"administration/fabrics/Spark-fabrics/databricks/ucshared","title":"Feature compatibility with UC clusters","description":"Gem support for Unity Catalog standard and dedicated access mode","permalink":"/administration/fabrics/Spark-fabrics/databricks/ucshared"},{"id":"getting-started/tutorials/spark-with-databricks","title":"Project lifecycle for Engineers","description":"Getting started with Spark on Databricks","permalink":"/engineers/project-lifecycle"},{"id":"administration/fabrics/Spark-fabrics/databricks/volumes-plibs","title":"Set up Prophecy libraries in Databricks volumes","description":"Add ProphecyLibs directly to volumes when Maven/PyPI is blocked on Databricks","permalink":"/admin/dbx-volumes-plibs"},{"id":"administration/fabrics/sql-fabrics/Fabrics","title":"SQL fabrics","description":"Perform SQL computations on a SQL warehouse","permalink":"/administration/fabrics/sql-fabrics/Fabrics"}],"unlisted":false}}')}}]);