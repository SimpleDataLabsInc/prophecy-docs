"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[40842],{7396:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"analysts/development/pipelines/execution","title":"Pipeline execution","description":"Run a set of defined operations in a pipeline","source":"@site/docs/analysts/development/pipelines/execution.md","sourceDirName":"analysts/development/pipelines","slug":"/analysts/pipeline-execution","permalink":"/analysts/pipeline-execution","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Pipeline execution","id":"execution","slug":"/analysts/pipeline-execution","description":"Run a set of defined operations in a pipeline","tags":[]},"sidebar":"mySidebar","previous":{"title":"Pipelines","permalink":"/analysts/pipelines"},"next":{"title":"Pipeline parameters","permalink":"/analysts/pipeline-parameters"}}');var s=t(74848),a=t(28453);const r={title:"Pipeline execution",id:"execution",slug:"/analysts/pipeline-execution",description:"Run a set of defined operations in a pipeline",tags:[]},o=void 0,l={},c=[{value:"Execution environment",id:"execution-environment",level:2},{value:"Methods of pipeline execution",id:"methods-of-pipeline-execution",level:2},{value:"Interactive runs in the canvas",id:"interactive-runs-in-the-canvas",level:3},{value:"Scheduled runs",id:"scheduled-runs",level:3},{value:"Executing pipelines via apps",id:"executing-pipelines-via-apps",level:3},{value:"External data handling",id:"external-data-handling",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["While SQL projects leverage ",(0,s.jsx)(n.a,{href:"https://docs.getdbt.com/docs/build/models",children:"dbt"})," for data transformations, pipeline execution is a hybrid process. This page describes how Prophecy executes pipelines in different scenarios."]}),"\n",(0,s.jsx)(n.h2,{id:"execution-environment",children:"Execution environment"}),"\n",(0,s.jsxs)(n.p,{children:["The execution environment defined in a ",(0,s.jsx)(n.a,{href:"/administration/fabrics/prophecy-fabrics/",children:"Prophecy fabric"})," consists of multiple compute engines."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"SQL warehouse"}),": Your own external SQL environment used to store tables, create tables, and execute queries. Transformations that run in the SQL warehouse are converted to dbt models under the hood. Learn more in ",(0,s.jsx)(n.a,{href:"/engineers/models",children:"Models"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Prophecy Automate"}),": Runtime that handles orchestration and the flow of external data from systems like Salesforce and Tableau in and out of the pipeline. To learn more, jump to ",(0,s.jsx)(n.a,{href:"#external-data-handling",children:"External data handling"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["To find more information about the relationship between these components, visit ",(0,s.jsx)(n.a,{href:"/administration/architecture",children:"Architecture"}),"."]})}),"\n",(0,s.jsx)(n.h2,{id:"methods-of-pipeline-execution",children:"Methods of pipeline execution"}),"\n",(0,s.jsx)(n.h3,{id:"interactive-runs-in-the-canvas",children:"Interactive runs in the canvas"}),"\n",(0,s.jsx)(n.p,{children:"Prophecy lets you interactively run your pipeline in the pipeline canvas and preview data transformations at every step. This helps you understand and validate your data transformations during development. There are two ways to start an interactive run:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Click the large play button on the bottom of the pipeline canvas."})," The whole pipeline runs."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Click the play button on a gem."})," All gems up to and including that gem run. This is a partial pipeline run."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["As gems run in your pipeline, sample outputs will appear after those gems. When you click on a data sample, Prophecy loads the data and opens the ",(0,s.jsx)(n.a,{href:"/analysts/data-explorer",children:"Data Explorer"}),". The Data Explorer lets you sort, filter, and search through the gem output."]}),"\n",(0,s.jsx)(n.h3,{id:"scheduled-runs",children:"Scheduled runs"}),"\n",(0,s.jsx)(n.p,{children:"Scheduling allows you to automate your data pipelines at predefined intervals. For each pipeline in your project, you can configure independent schedules that specify how often a pipeline runs and whether to send alerts during the automated runs. The execution environment of the scheduled run is determined during project publication."}),"\n",(0,s.jsxs)(n.p,{children:["To learn more about deploying projects to specific execution environments, see ",(0,s.jsx)(n.a,{href:"/analysts/versioning",children:"Versioning"})," and ",(0,s.jsx)(n.a,{href:"/analysts/scheduling",children:"Scheduling"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"executing-pipelines-via-apps",children:"Executing pipelines via apps"}),"\n",(0,s.jsxs)(n.p,{children:["You can also run pipelines with ",(0,s.jsx)(n.a,{href:"/analysts/business-applications",children:"Prophecy Apps"})," in Prophecy. These apps enable non-technical users to run data pipelines through intuitive, form-based interfaces. By restricting access to pipelines themselves, you can provide proper guardrails for pipeline execution via Prophecy Apps."]}),"\n",(0,s.jsx)(n.h2,{id:"external-data-handling",children:"External data handling"}),"\n",(0,s.jsxs)(n.p,{children:["Prophecy supports external sources and targets through ",(0,s.jsx)(n.a,{href:"/analysts/connections",children:"connections"}),". Because SQL transformations require structured ",(0,s.jsx)(n.a,{href:"/analysts/source-target/#tables",children:"tables"}),", Prophecy Automate dynamically creates temporary tables in your SQL warehouse to process this data."]}),"\n",(0,s.jsx)(n.p,{children:"Temporary tables act as intermediaries that allow external data to be processed using SQL logic. In other words, they enable dbt and SQL to transform external data as if it were native to the warehouse."}),"\n",(0,s.jsx)(n.p,{children:"Prophecy creates these tables during the pipeline run and removes them from the SQL warehouse after the run finishes. Temporary tables don\u2019t appear in the canvas."}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["Temporary tables use the following naming convention: ",(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"prophecy_tmp__{RUN_ID}__{PIPELINE_NAME}__{GEM/SOURCE_LABEL}[_{SUFFIX}]"})]})})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(96540);const s={},a=i.createContext(s);function r(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);