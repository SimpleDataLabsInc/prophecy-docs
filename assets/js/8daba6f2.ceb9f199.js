"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[53087],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(96540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},86632:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"release_notes/2025/3-4-3","title":"Prophecy 3.4.3.x","description":"Release notes for version 3.4.3","source":"@site/docs/release_notes/2025/3-4-3.md","sourceDirName":"release_notes/2025","slug":"/release_notes/2025/3-4-3","permalink":"/release_notes/2025/3-4-3","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"release notes","permalink":"/tags/release-notes"},{"inline":true,"label":"changelog","permalink":"/tags/changelog"},{"inline":true,"label":"january","permalink":"/tags/january"}],"version":"current","frontMatter":{"id":"3-4-3","description":"Release notes for version 3.4.3","title":"Prophecy 3.4.3.x","tags":["release notes","changelog","january"]},"sidebar":"mySidebar","previous":{"title":"Prophecy 3.4.4.x","permalink":"/release_notes/2025/3-4-4"},"next":{"title":"2024","permalink":"/release_notes/2024/"}}');var a=t(74848),s=t(28453);const r={id:"3-4-3",description:"Release notes for version 3.4.3",title:"Prophecy 3.4.3.x",tags:["release notes","changelog","january"]},o=void 0,l={},c=[{value:"Features",id:"features",level:2},{value:"Import functions from the Databricks Unity Catalog",id:"import-functions-from-the-databricks-unity-catalog",level:3},{value:"File upload in Spark pipelines",id:"file-upload-in-spark-pipelines",level:3},{value:"Updates",id:"Updates343",level:2},{value:"SCIM user experience enhancements",id:"scim-user-experience-enhancements",level:3},{value:"Machine-to-Machine functionality with Databricks OAuth",id:"machine-to-machine-functionality-with-databricks-oauth",level:3}];function h(e){const n={a:"a",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:"January 8, 2025"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Prophecy Python libs version: 1.9.29"}),"\n",(0,a.jsx)(n.li,{children:"Prophecy Scala libs version: 8.7.0"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,a.jsx)(n.h3,{id:"import-functions-from-the-databricks-unity-catalog",children:"Import functions from the Databricks Unity Catalog"}),"\n",(0,a.jsxs)(n.p,{children:["SQL UDFs stored in Databricks Unity Catalog are ",(0,a.jsx)(n.a,{href:"/Spark/functions/udfs#import-udfs",children:"now available for use"})," in Prophecy ",(0,a.jsx)(n.strong,{children:"Python"})," Projects."]}),"\n",(0,a.jsx)(n.h3,{id:"file-upload-in-spark-pipelines",children:"File upload in Spark pipelines"}),"\n",(0,a.jsx)(n.p,{children:"There are now three ways to upload a file and incorporate it into your Spark pipeline:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Drag and drop the file directly onto the pipeline canvas."}),"\n",(0,a.jsxs)(n.li,{children:["Open the Source/Target gem drawer and click ",(0,a.jsx)(n.strong,{children:"Upload file"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Create a new Source gem, click ",(0,a.jsx)(n.strong,{children:"+ New Dataset"}),", and then select ",(0,a.jsx)(n.strong,{children:"Upload file"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"Updates343",children:"Updates"}),"\n",(0,a.jsx)(n.h3,{id:"scim-user-experience-enhancements",children:"SCIM user experience enhancements"}),"\n",(0,a.jsxs)(n.p,{children:["When SCIM is enabled, there is a new option under ",(0,a.jsx)(n.strong,{children:"Settings > SSO"})," that lets you easily generate a SCIM token."]}),"\n",(0,a.jsx)(n.h3,{id:"machine-to-machine-functionality-with-databricks-oauth",children:"Machine-to-Machine functionality with Databricks OAuth"}),"\n",(0,a.jsxs)(n.p,{children:["This feature lets you use ",(0,a.jsx)(n.a,{href:"/databricks-oauth-authentication",children:"Databricks OAuth"})," for authentication during scheduled Jobs, as well as for Project releases and deployments. Visit the Databricks documentation to learn more about ",(0,a.jsx)(n.a,{href:"https://docs.databricks.com/en/dev-tools/auth/oauth-m2m.html",children:"access to Databricks with a Service Principal using OAuth"}),"."]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}}}]);