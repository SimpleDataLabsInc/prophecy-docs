"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[4400],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return h}});var o=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,i=function(e,t){if(null==e)return{};var n,o,i={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=o.createContext({}),p=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},u=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,i=e.mdxType,a=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=p(n),h=i,m=d["".concat(s,".").concat(h)]||d[h]||c[h]||a;return n?o.createElement(m,r(r({ref:t},u),{},{components:n})):o.createElement(m,r({ref:t},u))}));function h(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var a=n.length,r=new Array(a);r[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,r[1]=l;for(var p=2;p<a;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},69289:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return s},default:function(){return h},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return c}});var o=n(87462),i=n(63366),a=(n(67294),n(3905)),r=["components"],l={title:"Prophecy Build Tool",id:"prophecy-build-tool",description:"Prophecy Build tool",sidebar_position:4,tags:["metadata","build","deploy","test","cli","continuous integration","continuous deployment"]},s=void 0,p={unversionedId:"metadata/prophecy-build-tool",id:"metadata/prophecy-build-tool",title:"Prophecy Build Tool",description:"Prophecy Build tool",source:"@site/docs/metadata/prophecy-build-tool.md",sourceDirName:"metadata",slug:"/metadata/prophecy-build-tool",permalink:"/metadata/prophecy-build-tool",draft:!1,tags:[{label:"metadata",permalink:"/tags/metadata"},{label:"build",permalink:"/tags/build"},{label:"deploy",permalink:"/tags/deploy"},{label:"test",permalink:"/tags/test"},{label:"cli",permalink:"/tags/cli"},{label:"continuous integration",permalink:"/tags/continuous-integration"},{label:"continuous deployment",permalink:"/tags/continuous-deployment"}],version:"current",sidebarPosition:4,frontMatter:{title:"Prophecy Build Tool",id:"prophecy-build-tool",description:"Prophecy Build tool",sidebar_position:4,tags:["metadata","build","deploy","test","cli","continuous integration","continuous deployment"]},sidebar:"defaultSidebar",previous:{title:"Lineage",permalink:"/metadata/lineage"},next:{title:"Low-code Spark",permalink:"/low-code-spark/"}},u={},c=[{value:"Features (v1.0.1)",id:"features-v101",level:2},{value:"Requirements",id:"requirements",level:2},{value:"Installation",id:"installation",level:2},{value:"Quickstart",id:"quickstart",level:2},{value:"Usage",id:"usage",level:3},{value:"Running locally",id:"running-locally",level:3},{value:"Building Pipelines and deploying Jobs",id:"building-pipelines-and-deploying-jobs",level:4},{value:"Running all unit tests in project",id:"running-all-unit-tests-in-project",level:4},{value:"Integrating with Github Actions",id:"integrating-with-github-actions",level:2},{value:"Pre-requisite",id:"pre-requisite",level:3},{value:"Setting up environment variables and secrets",id:"setting-up-environment-variables-and-secrets",level:3},{value:"Setting up a Github Actions Workflow on every push to main branch",id:"setting-up-a-github-actions-workflow-on-every-push-to-main-branch",level:3}],d={toc:c};function h(e){var t=e.components,l=(0,i.Z)(e,r);return(0,a.kt)("wrapper",(0,o.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Prophecy-built-tool")," (PBT) allows you to quickly build, test and deploy projects generated by Prophecy (your standard Spark Scala and\nPySpark Pipelines) to integrate with your own CI / CD (e.g. Github Actions), build system (e.g. Jenkins), and\norchestration (e.g. Databricks Workflows)."),(0,a.kt)("h2",{id:"features-v101"},"Features (v1.0.1)"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Build and unit test all Pipelines in Prophecy projects (Scala and Python)"),(0,a.kt)("li",{parentName:"ul"},"Deploy Jobs with built Pipelines on Databricks"),(0,a.kt)("li",{parentName:"ul"},"Integrate with CI/CD tools like Github Actions"),(0,a.kt)("li",{parentName:"ul"},"Verify the project structure of Prophecy projects")),(0,a.kt)("h2",{id:"requirements"},"Requirements"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Python >=3.6"),(0,a.kt)("li",{parentName:"ul"},"pip")),(0,a.kt)("h2",{id:"installation"},"Installation"),(0,a.kt)("p",null,"To install PBT, simply run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"pip3 install prophecy-build-tool\n")),(0,a.kt)("h2",{id:"quickstart"},"Quickstart"),(0,a.kt)("h3",{id:"usage"},"Usage"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"Usage: pbt [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  build\n  deploy\n  test\n")),(0,a.kt)("h3",{id:"running-locally"},"Running locally"),(0,a.kt)("p",null,"The PBT cli can be used to build, test and deploy projects created by Prophecy that are present in your local filesystem."),(0,a.kt)("p",null,"Please make sure the ",(0,a.kt)("strong",{parentName:"p"},"DATABRICKS_URL")," and ",(0,a.kt)("strong",{parentName:"p"},"DATABRICKS_TOKEN")," environment variables are set appropriately pointing to your Databricks workspace before running any PBT commands.\nExample:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'export DATABRICKS_HOST="https://example_databricks_host.cloud.databricks.com"\nexport DATABRICKS_TOKEN="exampledatabrickstoken"\n')),(0,a.kt)("h4",{id:"building-pipelines-and-deploying-jobs"},"Building Pipelines and deploying Jobs"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"pbt deploy --path /path/to/your/prophecy_project/\n")),(0,a.kt)("p",null,"Sample output:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"Prophecy-build-tool v1.0.1\n\nFound 1 jobs: daily\nFound 1 pipelines: customers_orders (python)\n\nBuilding 1 pipelines \ud83d\udeb0\n\n  Building pipeline pipelines/customers_orders [1/1]\n\n\u2705 Build complete!\n\nDeploying 1 jobs \u23f1\n\n  Deploying job jobs/daily [1/1]\n    Uploading customers_orders-1.0-py3-none-any.whl to\ndbfs:/FileStore/prophecy/artifacts/...\nQuerying existing jobs to find current job: Offset: 0, Pagesize: 25\n    Updating an existing job: daily\n\n\u2705 Deployment completed successfully!\n")),(0,a.kt)("h4",{id:"running-all-unit-tests-in-project"},"Running all unit tests in project"),(0,a.kt)("p",null,"Running unit tests requires ",(0,a.kt)("strong",{parentName:"p"},"FABRIC_NAME")," environment variable to be set. This will be used to pick the correct configuration for running the unit tests. Example:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'export FABRIC_NAME="dev"\n')),(0,a.kt)("p",null,"To run all unit tests present in the project, use the ",(0,a.kt)("inlineCode",{parentName:"p"},"test")," command as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"pbt test --path /path/to/your/prophecy_project/\n")),(0,a.kt)("p",null,"Sample output:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"Prophecy-build-tool v1.0.1\n\nFound 1 jobs: daily\nFound 1 pipelines: customers_orders (python)\n\n  Unit Testing pipeline pipelines/customers_orders [1/1]\n\n    ============================= test session starts ==============================\n    platform darwin -- Python 3.8.9, pytest-7.1.2, pluggy-1.0.0 -- /Library/Developer/CommandLineTools/usr/bin/python\n    cachedir: .pytest_cache\n    metadata: None\n    rootdir: /path/to/your/prophecy_project/pipelines/customers_orders/code\n    plugins: html-3.1.1, metadata-2.0.2\n    collecting ... collected 1 item\n\n    test/TestSuite.py::CleanupTest::test_unit_test_0 PASSED                  [100%]\n\n    ============================== 1 passed in 17.42s ==============================\n\n\u2705 Unit test for pipeline: pipelines/customers_orders succeeded.\n")),(0,a.kt)("h2",{id:"integrating-with-github-actions"},"Integrating with Github Actions"),(0,a.kt)("p",null,"PBT can be integrated with your own CI/CD solution to build, test and deploy Prophecy code. The steps for setting up PBT with Github Actions on your repository containing a Prophecy project is mentioned below."),(0,a.kt)("h3",{id:"pre-requisite"},"Pre-requisite"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"A Prophecy project that is currently hosted in a Github repository")),(0,a.kt)("h3",{id:"setting-up-environment-variables-and-secrets"},"Setting up environment variables and secrets"),(0,a.kt)("p",null,"PBT requires environment variables ",(0,a.kt)("strong",{parentName:"p"},"DATABRICKS_URL, DATABRICKS_TOKEN")," and ",(0,a.kt)("strong",{parentName:"p"},"FABRIC_NAME")," to be set for complete functionality.\nSetting ",(0,a.kt)("strong",{parentName:"p"},"DATABRICKS_TOKEN")," as a secret in Github\nThe ",(0,a.kt)("strong",{parentName:"p"},"DATABRICKS_TOKEN")," that needs to be used can be set as a secret inside the Github repository of the project.\nSteps:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Go to Settings > Secrets > Actions from the repository menu"),(0,a.kt)("li",{parentName:"ul"},"Click \u2018New Repository secret\u2019"),(0,a.kt)("li",{parentName:"ul"},"Add the secret with name DATABRICKS_TOKEN and value of the Databricks token to be used by PBT.")),(0,a.kt)("p",null,"Screenshot after setting DATABRICKS_TOKEN secret:\n",(0,a.kt)("img",{alt:"Github Actions Secret addition",src:n(2942).Z,width:"2230",height:"1288"})),(0,a.kt)("p",null,"The environment variables can now be all set within the Github actions YML file as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},'env:\n  DATABRICKS_HOST: "https://sample_databricks_url.cloud.databricks.com"\n  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}\n  FABRIC_NAME: "dev"\n')),(0,a.kt)("p",null,"The complete YML file definition is discussed in the next section."),(0,a.kt)("h3",{id:"setting-up-a-github-actions-workflow-on-every-push-to-main-branch"},"Setting up a Github Actions Workflow on every push to main branch"),(0,a.kt)("p",null,"We\u2019re now ready to setup CI/CD on the Prophecy project.\nTo setup a workflow to build, run all unit tests and then deploy the built jar (Scala)/ whl (Python) on Databricks on every push to the main automatically:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Create a .YML file in the project repository at the below location (relative to root)")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},".github/workflows/exampleWorkflow.yml\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Add the below contents to ",(0,a.kt)("strong",{parentName:"li"},"exampleWorkflow.yml"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},'name: Example CI/CD with Github actions\n\non:\n  push:\n    branches:\n      - "main"\n\nenv:\n  DATABRICKS_HOST: "https://sample_databricks_url.cloud.databricks.com"\n  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}\n  FABRIC_NAME: "dev"\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up JDK 11\n        uses: actions/setup-java@v3\n        with:\n          java-version: "11"\n          distribution: "adopt"\n      - name: Set up Python 3.x\n        uses: actions/setup-python@v4\n        with:\n          python-version: "3.x"\n      # Install all python dependencies\n      # prophecy-libs not included here because prophecy-build-tool takes care of it by reading each pipeline\'s setup.py\n      - name: Install dependencies\n        run: |\n          python3 -m pip install --upgrade pip\n          pip3 install build pytest wheel pytest-html pyspark  prophecy-build-tool\n      - name: Run PBT build\n        run: pbt build --path .\n      - name: Run PBT test\n        run: pbt test --path .\n      - name: Run PBT deploy\n        run: pbt deploy --path .\n')),(0,a.kt)("p",null,"The above workflow does the following in order:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Triggers on every change that is pushed to the branch \u2018main\u2019"),(0,a.kt)("li",{parentName:"ol"},"Sets the environment variables required for PBT to run: DATABRICKS_HOST, DATABRICKS_TOKEN and FABRIC_NAME"),(0,a.kt)("li",{parentName:"ol"},"Sets up JDK 11, Python 3 and other dependencies required for PBT to run"),(0,a.kt)("li",{parentName:"ol"},"Builds all the Pipelines present in the project and generates a .jar/.whl file. If the build fails at any point a non-zero exit code is returned which stops the workflow from proceeding further and the workflow run is marked as a failure."),(0,a.kt)("li",{parentName:"ol"},"Runs all the unit tests present in the project using FABRIC_NAME as the configuration. If any of the unit test fails a non-zero exit code is returned which stops the workflow from proceeding further and the workflow run is marked as a failure."),(0,a.kt)("li",{parentName:"ol"},"Deploys the built .jar/.whl to the Databricks location mentioned in ",(0,a.kt)("inlineCode",{parentName:"li"},"databricks-job.json")," mentioned in the ",(0,a.kt)("inlineCode",{parentName:"li"},"jobs")," directory of the project. If the Job already exists in Databricks it is updated with the new .jar/.whl. If this process fails at any step, a non-zero exit code is returned which stops the workflow from proceeding further and the workflow run is marked as a failure.")))}h.isMDXComponent=!0},2942:function(e,t,n){t.Z=n.p+"assets/images/pbt-github-secret-b7e9a81b0279316b77fc4a01e9e20bcf.png"}}]);