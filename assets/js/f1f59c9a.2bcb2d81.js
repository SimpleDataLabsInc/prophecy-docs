"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[16389],{91619:e=>{e.exports=JSON.parse('{"label":"spark","permalink":"/tags/spark","allTagsPath":"/tags","count":23,"items":[{"id":"Spark/configuration","title":"Configurations","description":"Control how a pipeline behaves during execution","permalink":"/Spark/configuration"},{"id":"Spark/copilot-for-spark-users","title":"Copilot for Spark users","description":"Using Spark with Prophecy\'s Data Transformation Copilot","permalink":"/Spark/"},{"id":"Orchestration/airflow/prophecy-managed/connections/prophecy_managed_airflow_fabric_dbx_spark_connections","title":"Databricks Spark Connection","description":"How to create Databricks Spark connection in Prophecy Managed Airflow fabric","permalink":"/Orchestration/airflow/prophecy-managed/connections/prophecy_managed_airflow_fabric_dbx_spark_connections"},{"id":"Orchestration/pipeline-monitoring/enable-pipeline-monitoring","title":"Enable Pipeline Monitoring","description":"How to enable Pipeline Monitoring for Spark","permalink":"/Orchestration/pipeline-monitoring/enable-pipeline-monitoring"},{"id":"Spark/spark-streaming/streaming-sources-and-targets/streaming-event-apps","title":"Event-based","description":"Event-based Source and Target Gems for Streaming Data Applications","permalink":"/Spark/spark-streaming/streaming-sources-and-targets/streaming-event-apps"},{"id":"Spark/execution/execution-metrics","title":"Execution metrics","description":"Execution Metrics","permalink":"/Spark/execution/execution-metrics"},{"id":"Spark/execution/executions_on_databricks_clusters","title":"Execution on Databricks","description":"Execution on Databricks clusters","permalink":"/Spark/execution/executions_on_databricks_clusters"},{"id":"Spark/execution/executions_on_livy_clusters","title":"Execution on Livy","description":"Execution on Livy","permalink":"/Spark/execution/executions_on_livy_clusters"},{"id":"Spark/expression-builder","title":"Expression builder","description":"Expression Builder","permalink":"/Spark/expression-builder"},{"id":"Spark/spark-streaming/streaming-sources-and-targets/streaming-file-apps","title":"File-based","description":"File-based Source and Target gems for Streaming Data Applications","permalink":"/Spark/spark-streaming/streaming-sources-and-targets/streaming-file-apps"},{"id":"Spark/execution/interactive-execution","title":"Interactive execution","description":"Run a pipeline interactively in the pipeline canvas","permalink":"/Spark/execution/interactive-execution"},{"id":"Orchestration/pipeline-monitoring/pipeline-monitoring","title":"Pipeline Monitoring","description":"About Pipeline Monitoring for Spark","permalink":"/Orchestration/pipeline-monitoring/"},{"id":"Spark/pipeline-settings","title":"Pipeline settings","description":"Control how your pipeline runs","permalink":"/Spark/pipeline-settings"},{"id":"administration/secret-management/secret-management-spark","title":"Secret Management For Spark Fabrics","description":"Secret Management for Spark Fabrics","permalink":"/administration/secret-management/"},{"id":"Spark/gems/spark-gems","title":"Spark Gems","description":"Prophecy Spark Gems","permalink":"/Spark/gems/"},{"id":"getting-started/quick-starts/spark-onboarding","title":"Spark onboarding","description":"Follow along in the product to make your first Spark pipeline","permalink":"/getting-started/quick-starts/spark-onboarding"},{"id":"getting-started/tutorials/spark-with-databricks","title":"Spark with Databricks","description":"Getting started with Spark on Databricks","permalink":"/getting-started/tutorials/spark-with-databricks"},{"id":"Spark/spark-streaming/transformations-streaming","title":"Streaming Transformations","description":"Spark Streaming with Prophecy\'s easy-to-use interface","permalink":"/Spark/spark-streaming/transformations-streaming"},{"id":"ci-cd/tests","title":"Unit tests for Spark","description":"Implementing unit tests in Prophecy","permalink":"/ci-cd/tests"},{"id":"Spark/gems/source-target/file/upload-file","title":"Upload files","description":"Upload files to your Spark pipeline","permalink":"/Spark/gems/source-target/file/upload-file"},{"id":"Spark/best-practices/use-dbx-secrets","title":"Use Databricks Secrets for Username Password fields in Gems","description":"Databricks secrets for username and passwords","permalink":"/Spark/best-practices/use-dbx-secrets"},{"id":"Orchestration/pipeline-monitoring/use-pipeline-monitoring","title":"Use Pipeline Monitoring","description":"How to use Pipeline Monitoring for Spark","permalink":"/Orchestration/pipeline-monitoring/use-pipeline-monitoring"},{"id":"Spark/spark-streaming/streaming-sources-and-targets/streaming-warehouse-apps","title":"Warehouse-based","description":"Warehouse-based Source gem for Streaming Data Applications","permalink":"/Spark/spark-streaming/streaming-sources-and-targets/streaming-warehouse-apps"}]}')}}]);