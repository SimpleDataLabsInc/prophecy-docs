"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[2537],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var o=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=o.createContext({}),p=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(n),m=a,h=d["".concat(s,".").concat(m)]||d[m]||u[m]||r;return n?o.createElement(h,i(i({ref:t},c),{},{components:n})):o.createElement(h,i({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,i=new Array(r);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var p=2;p<r;p++)i[p]=n[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},6301:function(e,t,n){n.r(t),n.d(t,{assets:function(){return c},contentTitle:function(){return s},default:function(){return m},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return u}});var o=n(7462),a=n(3366),r=(n(7294),n(3905)),i=["components"],l={title:"Reliable CI/CD with Prophecy",image:"img/reliable-ci-cd/dev-qa-prod.png",id:"reliable-ci-cd",description:"Explore Continuous Integration and Continuous Delivery within Prophecy",sidebar_position:2,tags:["cicd","deployment","devops","qa","testing","tutorial"]},s=void 0,p={unversionedId:"tutorials/low-code-jobs/reliable-ci-cd",id:"tutorials/low-code-jobs/reliable-ci-cd",title:"Reliable CI/CD with Prophecy",description:"Explore Continuous Integration and Continuous Delivery within Prophecy",source:"@site/docs/tutorials/low-code-jobs/reliable-ci-cd.md",sourceDirName:"tutorials/low-code-jobs",slug:"/tutorials/low-code-jobs/reliable-ci-cd",permalink:"/tutorials/low-code-jobs/reliable-ci-cd",draft:!1,tags:[{label:"cicd",permalink:"/tags/cicd"},{label:"deployment",permalink:"/tags/deployment"},{label:"devops",permalink:"/tags/devops"},{label:"qa",permalink:"/tags/qa"},{label:"testing",permalink:"/tags/testing"},{label:"tutorial",permalink:"/tags/tutorial"}],version:"current",sidebarPosition:2,frontMatter:{title:"Reliable CI/CD with Prophecy",image:"img/reliable-ci-cd/dev-qa-prod.png",id:"reliable-ci-cd",description:"Explore Continuous Integration and Continuous Delivery within Prophecy",sidebar_position:2,tags:["cicd","deployment","devops","qa","testing","tutorial"]},sidebar:"defaultSidebar",previous:{title:"Multi Jobs Trigger",permalink:"/tutorials/low-code-jobs/multi-jobs-trigger"},next:{title:"Low-code Spark",permalink:"/category/low-code-spark"}},c={},u=[{value:"Single-fabric Development",id:"single-fabric-development",level:2},{value:"Multi-fabric Deployment with Prophecy",id:"multi-fabric-deployment-with-prophecy",level:2},{value:"Why so many environments?",id:"why-so-many-environments",level:3},{value:"Development and Production",id:"development-and-production",level:3},{value:"Entities setup",id:"entities-setup",level:4},{value:"Development &amp; Testing",id:"development--testing",level:4},{value:"Deployment to Production",id:"deployment-to-production",level:4},{value:"Multi-fabric Deployment with GitHub",id:"multi-fabric-deployment-with-github",level:2}],d={toc:u};function m(e){var t=e.components,l=(0,a.Z)(e,i);return(0,r.kt)("wrapper",(0,o.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Continuous Integration (CI)")," and ",(0,r.kt)("strong",{parentName:"p"},"Continuous Delivery (CD)")," are some of the cornerstones of modern and reliable\nsoftware engineering practices. To iterate quickly on the software, engineers push code as often as possible to their\nmain GIT branch (branch shared by all the teammates). The ",(0,r.kt)("strong",{parentName:"p"},"CI")," process automatically tests the pushed code, by running\nunit & integration tests, to avoid any future challenges. After the team has decided that their new code is ready to be\ndeployed to production, the ",(0,r.kt)("strong",{parentName:"p"},"CD")," process automatically deploys all the changes after they've been tested in the\nproduction environment."),(0,r.kt)("p",null,"For a CI/CD process to work efficiently, the engineers often work and test their code in multiple different\nenvironments.\nA common example is a setup with three stages: ",(0,r.kt)("strong",{parentName:"p"},"Development"),", ",(0,r.kt)("strong",{parentName:"p"},"QA"),", ",(0,r.kt)("strong",{parentName:"p"},"Production"),"."),(0,r.kt)("p",null,"Those practices have been applied to software engineering for many years now and enabled a lot of organizations to\ndeploy reliably their code even ",(0,r.kt)("strong",{parentName:"p"},"many times a day"),"! However, even today, the vast majority of data practitioners are\nstill struggling with operationalizing their code."),(0,r.kt)("p",null,"This has been mostly caused by",(0,r.kt)("strong",{parentName:"p"}," difficult to work with formats")," (like notebooks or proprietary ETL binaries) that\naren't easily versioned and stored in GIT, and lack of access to ",(0,r.kt)("strong",{parentName:"p"},"well-modeled synthetic data")," for lower environments.\nAdditionally, data users are often not used to working with technologies like GIT, which have a very steep learning\ncurve."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Data Pipeline",src:n(2500).Z,width:"3000",height:"1604"})),(0,r.kt)("p",null,"Here comes Prophecy! Since Prophecy works very similarly to a ",(0,r.kt)("strong",{parentName:"p"},"code-based IDE")," with an additional ",(0,r.kt)("strong",{parentName:"p"},"low-code\nproductivity\nlayer"),", all your code for data pipelines and jobs is directly accessible to you and stored in GIT. This enables any\ndata\npractitioners to leverage the ",(0,r.kt)("strong",{parentName:"p"},"best DevOps practices easily"),"."),(0,r.kt)("h2",{id:"single-fabric-development"},"Single-fabric Development"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Minimum project setup",src:n(694).Z,width:"3200",height:"1338"})),(0,r.kt)("p",null,"First of all, let's consider, the ",(0,r.kt)("strong",{parentName:"p"},"simplest scenario"),", where you have only a single execution environment (e.g a\nsingle Databricks\nworkspace). In those cases, usually, everyone on your team has access to that environment. Everyone does both the\ndevelopment and productionization of your pipelines in the same place."),(0,r.kt)("p",null,"In Prophecy, at minimum, you will find yourself having:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"multiple projects")," - your GIT repositories which store all the Spark, Airflow, and metadata code"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"multiple data pipelines")," - various ETL / ELT tasks written in Spark"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"multiple jobs")," - the orchestration of your data pipelines written in Databricks Jobs or Airflow"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"a single team")," - all your teammates in the same place, with the same access"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"a single fabric")," - the connection to your Databricks workspace")),(0,r.kt)("p",null,"This is great for simple setups and very small teams, but can quickly lead to many problems. In such a setup, it's very\neasy for you and your teammates to make mistakes and ",(0,r.kt)("strong",{parentName:"p"},"accidentally affect production")," pipelines. There's also ",(0,r.kt)("strong",{parentName:"p"},"lack\nof data\nseparation"),", so any PII information becomes visible to everyone!"),(0,r.kt)("p",null,"A better approach is to have physical environments, connected to different stages of development. A common example is a\nsetup with three stages: ",(0,r.kt)("strong",{parentName:"p"},"Development"),", ",(0,r.kt)("strong",{parentName:"p"},"QA"),", ",(0,r.kt)("strong",{parentName:"p"},"Production"),". Each environment has usually its independent data,\nmetastore, clusters, and even permissions."),(0,r.kt)("h2",{id:"multi-fabric-deployment-with-prophecy"},"Multi-fabric Deployment with Prophecy"),(0,r.kt)("p",null,"Let's consider a better alternative to a single environment development."),(0,r.kt)("h3",{id:"why-so-many-environments"},"Why so many environments?"),(0,r.kt)("p",null,"The simplest alternative involves adding just one more execution environment called ",(0,r.kt)("strong",{parentName:"p"},"production"),"."),(0,r.kt)("p",null,"By separating your ",(0,r.kt)("strong",{parentName:"p"},"development")," or QA use-cases from your ",(0,r.kt)("strong",{parentName:"p"},"production")," use-cases, you get:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"PII safety (by using mock or anonymized data)"),(0,r.kt)("li",{parentName:"ul"},"Faster development (by using smaller data samples)"),(0,r.kt)("li",{parentName:"ul"},"Reduced development costs (by using smaller cluster sizes)"),(0,r.kt)("li",{parentName:"ul"},"Increased data quality confidence (by only pushing code after tests and validations pass)")),(0,r.kt)("p",null,"You can push your code to the ",(0,r.kt)("strong",{parentName:"p"},"production environment")," only after you're confident it's going to work well. The\nproduction environment has access to your real data, uses large optimal clusters, and has significantly restricted\naccess. In some cases, only the operational support teams should have access to your production environment."),(0,r.kt)("p",null,"If you'd like to involve more stages, to even further increase the reliability of your development process, you can add\na ",(0,r.kt)("strong",{parentName:"p"},"QA environment"),". That environment should have data, hardware, and software that closely simulates the Production\nenvironment (e.g. data slices directly taken from production), and should serve as a holding area. Using QA, your\nengineers make sure that the jobs are going to run smoothly in the production environment, without actually potentially\nbreaking production, if some code is wrong."),(0,r.kt)("h3",{id:"development-and-production"},"Development and Production"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Prophecy Setup",src:n(949).Z,width:"3200",height:"2006"})),(0,r.kt)("p",null,"For our example, however, let's focus on a setup with two environments: ",(0,r.kt)("strong",{parentName:"p"},"Development")," & ",(0,r.kt)("strong",{parentName:"p"},"Production"),". Our\n",(0,r.kt)("strong",{parentName:"p"},"Development environment")," is accessible to our whole organization (developers, analysts, support) and is connected to\nour development Databricks workspace, which contains only dummy customer data. Whereas, our ",(0,r.kt)("strong",{parentName:"p"},"Production environment"),"\nis only accessible to our production support team and is connected to our production Databricks workspace, which has\nreal customer data."),(0,r.kt)("h4",{id:"entities-setup"},"Entities setup"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create two ",(0,r.kt)("strong",{parentName:"p"},"teams"),":"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"developers")," - a superset of all the teams, which contains your developers and members of the ",(0,r.kt)("em",{parentName:"li"},"prod_support"),"\nteam"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"prod_support")," - team composed of members who have privileged production access permissions"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create two ",(0,r.kt)("strong",{parentName:"p"},"fabrics"),":"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"development")," - owned by the ",(0,r.kt)("em",{parentName:"li"},"developers")," team"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"production")," - owned by the ",(0,r.kt)("em",{parentName:"li"},"prod_support")," team"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Set up your ",(0,r.kt)("strong",{parentName:"p"},"projects")," - create your projects, as you would before. Projects should be owned by the ",(0,r.kt)("em",{parentName:"p"},"developers"),"\nteam.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Set up your ",(0,r.kt)("strong",{parentName:"p"},"jobs")," - for every single set of pipelines you'd like to schedule, create two jobs:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"job_development")," - jobs built by the ",(0,r.kt)("em",{parentName:"li"},"developers")," for integration and testing purposes"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"job_production")," - jobs built by the ",(0,r.kt)("em",{parentName:"li"},"prod_support")," team, based on the development jobs - they will run in the\nproduction environment")))),(0,r.kt)("div",{style:{position:"relative","padding-bottom":"56.25%",height:0}},(0,r.kt)("iframe",{src:"https://www.loom.com/embed/b9669f374f504e469b2f88374bcf35d3",frameborder:"0",webkitallowfullscreen:!0,mozallowfullscreen:!0,allowfullscreen:!0,style:{position:"absolute",top:0,left:0,width:"100%",height:"100%"}})),(0,r.kt)("h4",{id:"development--testing"},"Development & Testing"),(0,r.kt)("p",null,"Phew, that was a lot of work! But the biggest chunk is behind us \ud83d\udcaa."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Run Progress",src:n(2317).Z,width:"8212",height:"2322"})),(0,r.kt)("p",null,"Now that we have set up our fabrics and teams, built some pipelines, it's time to test the whole data flow on our\ndevelopment environment."),(0,r.kt)("p",null,"Testing your pipelines and jobs is very simple. Simple click on the play button and watch your code run!"),(0,r.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"Coming Soon")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Note, that currently, we're spinning up a new cluster for each of the tasks, therefore your job might take a few minutes\nto complete. However, soon, you will be able to have granular control over which pipeline runs on which cluster."))),(0,r.kt)("h4",{id:"deployment-to-production"},"Deployment to Production"),(0,r.kt)("p",null,"Once we're confident that our job works correctly, and we have tested it well, we can start deploying it to our\n",(0,r.kt)("strong",{parentName:"p"},"production")," environment. In our setup, only a production support engineer can do that. Therefore, login as them,\nduplicate your job on the production fabric, set appropriate pipeline configurations and enable it."),(0,r.kt)("p",null,"That's it! Now you can commit any remaining changes and release your pipeline. Prophecy automatically takes care of the\nrelease process, by building your pipelines, running unit tests, and finally deploying the pipeline jars/wheels\nalongside the job definition directly to Databricks (or AirFlow)."),(0,r.kt)("p",null,"If you're new to this process, check out, our ",(0,r.kt)("a",{parentName:"p",href:"/metadata/git"},"GIT"),"\nand ",(0,r.kt)("a",{parentName:"p",href:"/low-code-jobs/databricks-jobs#deployment"},"jobs deployment")," documentation."),(0,r.kt)("div",{style:{position:"relative","padding-bottom":"56.25%",height:0}},(0,r.kt)("iframe",{src:"https://www.loom.com/embed/28153636876f409184e6ba2dcbc8f273",frameborder:"0",webkitallowfullscreen:!0,mozallowfullscreen:!0,allowfullscreen:!0,style:{position:"absolute",top:0,left:0,width:"100%",height:"100%"}})),(0,r.kt)("h2",{id:"multi-fabric-deployment-with-github"},"Multi-fabric Deployment with GitHub"),(0,r.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"Coming Soon")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"})))}m.isMDXComponent=!0},2500:function(e,t,n){t.Z=n.p+"assets/images/dev-qa-prod-be4c5dab33d67936196d5f3660e0e263.png"},694:function(e,t,n){t.Z=n.p+"assets/images/min-project-setup-4098dd2390227337f38e9acda6980177.png"},949:function(e,t,n){t.Z=n.p+"assets/images/prophecy-setup-73170a1782cb0235e9e92461bb2741c9.png"},2317:function(e,t,n){t.Z=n.p+"assets/images/run-progress-e5e5c558ac5f7224b0cff9b62f14eecb.png"}}]);