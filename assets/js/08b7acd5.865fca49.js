"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[20767],{15680:(e,n,a)=>{a.d(n,{xA:()=>m,yg:()=>d});var i=a(96540);function t(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,i)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach((function(n){t(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,i,t=function(e,n){if(null==e)return{};var a,i,t={},r=Object.keys(e);for(i=0;i<r.length;i++)a=r[i],n.indexOf(a)>=0||(t[a]=e[a]);return t}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)a=r[i],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var p=i.createContext({}),s=function(e){var n=i.useContext(p),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},m=function(e){var n=s(e.components);return i.createElement(p.Provider,{value:n},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},y=i.forwardRef((function(e,n){var a=e.components,t=e.mdxType,r=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=s(a),y=t,d=c["".concat(p,".").concat(y)]||c[y]||u[y]||r;return a?i.createElement(d,l(l({ref:n},m),{},{components:a})):i.createElement(d,l({ref:n},m))}));function d(e,n){var a=arguments,t=n&&n.mdxType;if("string"==typeof e||t){var r=a.length,l=new Array(r);l[0]=y;var o={};for(var p in n)hasOwnProperty.call(n,p)&&(o[p]=n[p]);o.originalType=e,o[c]="string"==typeof e?e:t,l[1]=o;for(var s=2;s<r;s++)l[s]=a[s];return i.createElement.apply(null,l)}return i.createElement.apply(null,a)}y.displayName="MDXCreateElement"},64914:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>p,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>s});var i=a(58168),t=(a(96540),a(15680));const r={title:"Alternative Schedulers",id:"alternative-schedulers",description:"Support for Alternative Orchestration Solutions",tags:["jobs","deployment","orchestration","spark-submit","runtime config"]},l=void 0,o={unversionedId:"Orchestration/alternative-schedulers",id:"Orchestration/alternative-schedulers",title:"Alternative Schedulers",description:"Support for Alternative Orchestration Solutions",source:"@site/docs/Orchestration/alternative-schedulers.md",sourceDirName:"Orchestration",slug:"/Orchestration/alternative-schedulers",permalink:"/Orchestration/alternative-schedulers",draft:!1,tags:[{label:"jobs",permalink:"/tags/jobs"},{label:"deployment",permalink:"/tags/deployment"},{label:"orchestration",permalink:"/tags/orchestration"},{label:"spark-submit",permalink:"/tags/spark-submit"},{label:"runtime config",permalink:"/tags/runtime-config"}],version:"current",frontMatter:{title:"Alternative Schedulers",id:"alternative-schedulers",description:"Support for Alternative Orchestration Solutions",tags:["jobs","deployment","orchestration","spark-submit","runtime config"]}},p={},s=[{value:"Basic Spark Submit",id:"basic-spark-submit",level:2},{value:"Scala Spark Pipelines",id:"scala-spark-pipelines",level:3},{value:"PySpark Pipelines",id:"pyspark-pipelines",level:3},{value:"Set Runtime Configuration variables",id:"set-runtime-configuration-variables",level:3},{value:"<code>-i</code> set the Pipeline Configuration instance",id:"-i-set-the-pipeline-configuration-instance",level:4},{value:"<code>-i</code> examples",id:"-i-examples",level:5},{value:"<code>-O</code> override many parameters as a json blob",id:"-o-override-many-parameters-as-a-json-blob",level:4},{value:"<code>-0</code> examples",id:"-0-examples",level:5},{value:"<code>-C</code> override individual parameters",id:"-c-override-individual-parameters",level:4},{value:"<code>-C</code> examples",id:"-c-examples",level:5},{value:"<code>-f</code> set configuration using a file",id:"-f-set-configuration-using-a-file",level:4},{value:"<code>-f</code> examples",id:"-f-examples",level:5}],m={toc:s},c="wrapper";function u(e){let{components:n,...a}=e;return(0,t.yg)(c,(0,i.A)({},m,a,{components:n,mdxType:"MDXLayout"}),(0,t.yg)("h2",{id:"basic-spark-submit"},"Basic Spark Submit"),(0,t.yg)("p",null,"The following sections contain Scala, PySpark and runtime configuration variables to use with custom orchestration solutions."),(0,t.yg)("h3",{id:"scala-spark-pipelines"},"Scala Spark Pipelines"),(0,t.yg)("p",null,"Prerequisites:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Optional: Modify ",(0,t.yg)("inlineCode",{parentName:"li"},"ivysettings.xml")," to point to a custom Maven mirror.")),(0,t.yg)("p",null,'Given a Scala Pipeline named "demo_pipeline" with a JAR artifact from ',(0,t.yg)("a",{parentName:"p",href:"/ci-cd/prophecy-build-tool/"},"PBT"),"\ncalled ",(0,t.yg)("inlineCode",{parentName:"p"},"demo_pipeline-1.0.jar")," you could call the following commands to invoke the Main class from the JAR\nfile and run the Pipeline on a local Spark cluster."),(0,t.yg)("admonition",{type:"caution"},(0,t.yg)("p",{parentName:"admonition"},"Make sure to use the correct version of ",(0,t.yg)("inlineCode",{parentName:"p"},"io.prophecy:prophecy-libs_2.12")," for your Pipeline.\nFind this version in the ",(0,t.yg)("inlineCode",{parentName:"p"},"pom.xml")," or ",(0,t.yg)("inlineCode",{parentName:"p"},"pbt_project.yml")," in the Pipeline's source code directory.\nAlternatively use a tool like ",(0,t.yg)("inlineCode",{parentName:"p"},"jdeps")," on the jar file itself.")),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-shell"},'spark-submit \\\n  --master yarn \\\n  --deploy-mode cluster \\\n  --driver-memory 8g \\\n  --executor-memory 4g \\\n  --executor-cores 4  \\\n  --packages io.prophecy:prophecy-libs_2.12:3.5.0-8.0.29 \\\n  --class io.prophecy.pipelines.demo_pipeline.Main \\\n  demo_pipeline-1.0.jar -i default -O "{}"\n')),(0,t.yg)("h3",{id:"pyspark-pipelines"},"PySpark Pipelines"),(0,t.yg)("p",null,"Prerequisites:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},"Install Python dependencies by installing the WHL file using ",(0,t.yg)("inlineCode",{parentName:"li"},"pip"),".",(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("inlineCode",{parentName:"li"},"pip install ./demo_pipeline-1.0-py3-none-any.whl")))),(0,t.yg)("li",{parentName:"ul"},"Gather necessary Maven dependencies and put into the ",(0,t.yg)("inlineCode",{parentName:"li"},"--jars")," (local) or ",(0,t.yg)("inlineCode",{parentName:"li"},"--packages")," (repo) option.",(0,t.yg)("ul",{parentName:"li"},(0,t.yg)("li",{parentName:"ul"},"PBT will have a command to generate dependencies or pom.xml for PySpark projects."))),(0,t.yg)("li",{parentName:"ul"},"Optional: Modify ivysettings.xml to point to a custom Maven mirror or PyPi mirror.")),(0,t.yg)("p",null,'Given a PySpark Pipeline named "demo_pipeline" with a WHL artifact from ',(0,t.yg)("a",{parentName:"p",href:"/ci-cd/prophecy-build-tool/"},"PBT"),"\ncalled ",(0,t.yg)("inlineCode",{parentName:"p"},"demo_pipeline-1.0-py3-none-any.whl")," you could call the following commands to invoke the ",(0,t.yg)("inlineCode",{parentName:"p"},"main()")," method from the WHL\nfile using a customized launcher script."),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-shell"},' spark-submit \\\n  --master yarn \\\n  --deploy-mode cluster \\\n  --driver-memory 8g \\\n  --executor-memory 4g \\\n  --executor-cores 4  \\\n  --packages io.prophecy:prophecy-libs_2.12:3.5.0-8.0.29 \\\n  --py-files demo_pipeline-1.0-py3-none-any.whl \\\n  launcher.py -i default -O "{}"\n')),(0,t.yg)("p",null,"In this example ",(0,t.yg)("inlineCode",{parentName:"p"},"launcher.py")," would import the whl file and call the ",(0,t.yg)("inlineCode",{parentName:"p"},"main()")," entrypoint like so:"),(0,t.yg)("admonition",{type:"caution"},(0,t.yg)("p",{parentName:"admonition"},"This launcher must import the name of your specific Pipeline package!")),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-python"},"from demo_pipeline import main\n\nmain()\n")),(0,t.yg)("h3",{id:"set-runtime-configuration-variables"},"Set Runtime Configuration variables"),(0,t.yg)("p",null,'In some cases you may want to override runtime configuration variables of a Pipeline.\nWe offer several options for changing the Pipeline configuration at runtime. Each example will show a sample\nas "parameters" (e.g. for a Databricks Job) and as "sys args" (e.g. for passing at the end of a ',(0,t.yg)("inlineCode",{parentName:"p"},"spark-submit")," command)."),(0,t.yg)("p",null,"Sample Configuration Schema for below examples:"),(0,t.yg)("table",null,(0,t.yg)("thead",{parentName:"table"},(0,t.yg)("tr",{parentName:"thead"},(0,t.yg)("th",{parentName:"tr",align:null},"Name"),(0,t.yg)("th",{parentName:"tr",align:null},"Type"))),(0,t.yg)("tbody",{parentName:"table"},(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},"str_var"),(0,t.yg)("td",{parentName:"tr",align:null},"string")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},"bool_var"),(0,t.yg)("td",{parentName:"tr",align:null},"boolean")),(0,t.yg)("tr",{parentName:"tbody"},(0,t.yg)("td",{parentName:"tr",align:null},"float_var"),(0,t.yg)("td",{parentName:"tr",align:null},"float")))),(0,t.yg)("h4",{id:"-i-set-the-pipeline-configuration-instance"},(0,t.yg)("inlineCode",{parentName:"h4"},"-i")," set the Pipeline Configuration instance"),(0,t.yg)("p",null,"A Pipeline may be run with a different Pipeline Configuration instance by using the ",(0,t.yg)("inlineCode",{parentName:"p"},"-i")," option and providing the name of the configuration profile instance. For more information on configuration instances and overrides, see ",(0,t.yg)("a",{parentName:"p",href:"../../Spark/configuration/#pipeline-configuration-instances"},"Pipeline Configuration instances"),"."),(0,t.yg)("h5",{id:"-i-examples"},(0,t.yg)("inlineCode",{parentName:"h5"},"-i")," examples"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as parameters: ",(0,t.yg)("inlineCode",{parentName:"p"},"['-i', 'default']"))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as sysargs: ",(0,t.yg)("inlineCode",{parentName:"p"},"-i default")))),(0,t.yg)("h4",{id:"-o-override-many-parameters-as-a-json-blob"},(0,t.yg)("inlineCode",{parentName:"h4"},"-O")," override many parameters as a json blob"),(0,t.yg)("p",null,"This may be used in conjunction with ",(0,t.yg)("inlineCode",{parentName:"p"},"-i")," and it will only override parameters which are given. You must\nspecify the name and value of each variable that you want to override."),(0,t.yg)("h5",{id:"-0-examples"},(0,t.yg)("inlineCode",{parentName:"h5"},"-0")," examples"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as parameters: ",(0,t.yg)("inlineCode",{parentName:"p"},'[\'-O\', \'{"str_var":"overridden", "float_var":0.5}\']'))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as sysargs: ",(0,t.yg)("inlineCode",{parentName:"p"},'-O "{\\"str_var\\":\\"overridden\\",\\"float_var\\":0.5}"')))),(0,t.yg)("h4",{id:"-c-override-individual-parameters"},(0,t.yg)("inlineCode",{parentName:"h4"},"-C")," override individual parameters"),(0,t.yg)("p",null,"This may be used in conjunction with ",(0,t.yg)("inlineCode",{parentName:"p"},"-i")," and it will only override parameters which are given.\nThis option may be used more than once."),(0,t.yg)("h5",{id:"-c-examples"},(0,t.yg)("inlineCode",{parentName:"h5"},"-C")," examples"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as parameters: ",(0,t.yg)("inlineCode",{parentName:"p"},"['-C', 'str_var=test1', 'float_var=0.5']"))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as sysargs: ",(0,t.yg)("inlineCode",{parentName:"p"},"-C str_var=test1 float_var=0.5")))),(0,t.yg)("h4",{id:"-f-set-configuration-using-a-file"},(0,t.yg)("inlineCode",{parentName:"h4"},"-f")," set configuration using a file"),(0,t.yg)("p",null,"This option will set all parameters for a Pipeline by using a json file which can be reached locally by the\n",(0,t.yg)("inlineCode",{parentName:"p"},"spark-submit")," command."),(0,t.yg)("admonition",{type:"caution"},(0,t.yg)("p",{parentName:"admonition"},"All Configuration Schema fields must be provided in this file.")),(0,t.yg)("h5",{id:"-f-examples"},(0,t.yg)("inlineCode",{parentName:"h5"},"-f")," examples"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as parameters: ",(0,t.yg)("inlineCode",{parentName:"p"},"['-f', '/path/to/somefile.json']"))),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"as sysargs: ",(0,t.yg)("inlineCode",{parentName:"p"},"-f /path/to/somefile.json")))),(0,t.yg)("p",null,"Example json file:"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-json"},'{\n  "str_var": "vendor1",\n  "bool_var": true,\n  "float_var": 0.5\n}\n')))}u.isMDXComponent=!0}}]);