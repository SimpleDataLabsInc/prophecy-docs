"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[94735],{28453:(e,s,r)=>{r.d(s,{R:()=>a,x:()=>c});var t=r(96540);const i={},n=t.createContext(i);function a(e){const s=t.useContext(n);return t.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function c(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(n.Provider,{value:s},e.children)}},60359:(e,s,r)=>{r.r(s),r.d(s,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"administration/secrets/secret-providers","title":"Secrets for Spark pipelines","description":"Create secrets to reference in Spark pipelines","source":"@site/docs/administration/secrets/secret-providers.md","sourceDirName":"administration/secrets","slug":"/engineers/secrets","permalink":"/engineers/secrets","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"secrets","permalink":"/tags/secrets"},{"inline":true,"label":"connections","permalink":"/tags/connections"}],"version":"current","frontMatter":{"title":"Secrets for Spark pipelines","id":"secret-providers","description":"Create secrets to reference in Spark pipelines","slug":"/engineers/secrets","tags":["secrets","connections"]},"sidebar":"platformSidebar","previous":{"title":"Google BigQuery SQL","permalink":"/administration/fabrics/sql-fabrics/bigquery"},"next":{"title":"Pipeline development","permalink":"/engineers/pipeline-development"}}');var i=r(74848),n=r(28453);const a={title:"Secrets for Spark pipelines",id:"secret-providers",description:"Create secrets to reference in Spark pipelines",slug:"/engineers/secrets",tags:["secrets","connections"]},c=void 0,o={},l=[{value:"Access control",id:"access-control",level:2},{value:"Using secrets in pipelines",id:"using-secrets-in-pipelines",level:2},{value:"Secret providers",id:"secret-providers",level:2},{value:"Databricks",id:"databricks",level:3},{value:"HashiCorp Vault",id:"hashicorp-vault",level:3},{value:"Environment variables",id:"environment-variables",level:3}];function d(e){const s={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.admonition,{title:"Enterprise Only",type:"edition",children:(0,i.jsxs)(s.p,{children:["Available only in ",(0,i.jsx)(s.a,{href:"/getting-started/editions/",children:"Enterprise Edition"}),"."]})}),"\n",(0,i.jsxs)(s.p,{children:["A ",(0,i.jsx)(s.em,{children:"secret"})," is sensitive information\u2014such as an API key, password, or encryption key\u2014that you want to use in a pipeline without exposing its value. A ",(0,i.jsx)(s.a,{href:"#secret-providers",children:"secret provider"})," is a storage system that manages those secrets securely (for example, Databricks Secrets, HashiCorp Vault, or environment variables)."]}),"\n",(0,i.jsx)(s.p,{children:"To leverage secrets and external secret providers in Prophecy, secrets must be stored in a fabric. This ensures that the compute attached to that fabric can access the secret at runtime while keeping the value hidden from users. By linking providers to fabrics, you can safely pass credentials and keys into Spark pipelines without hardcoding them."}),"\n",(0,i.jsx)(s.h2,{id:"access-control",children:"Access control"}),"\n",(0,i.jsx)(s.p,{children:"Secrets belong to the fabric where they are created. Anyone with access to the fabric can reference them in projects."}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Users can ",(0,i.jsx)(s.strong,{children:"use"})," secrets in gems or configurations."]}),"\n",(0,i.jsxs)(s.li,{children:["Users cannot ",(0,i.jsx)(s.strong,{children:"see"})," the raw secret values."]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"using-secrets-in-pipelines",children:"Using secrets in pipelines"}),"\n",(0,i.jsx)(s.p,{children:"When a gem requires authentication fields (for example, username or password), you can insert a secret instead of entering plain text."}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsx)(s.li,{children:"Click Insert Secret in the gem field. A dropdown lists all secrets from the selected fabric."}),"\n",(0,i.jsx)(s.li,{children:"If a secret is missing, check the fabric selection (top-right corner)."}),"\n",(0,i.jsx)(s.li,{children:"Attach a cluster to enable Refresh Secrets for the provider."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{alt:"use_secret",src:r(81195).A+"",width:"2880",height:"1084"})}),"\n",(0,i.jsx)(s.admonition,{type:"info",children:(0,i.jsx)(s.p,{children:"Typing credentials directly into fields triggers a warning diagnostic."})}),"\n",(0,i.jsx)(s.admonition,{type:"tip",children:(0,i.jsxs)(s.p,{children:["If you want to populate secrets dynamically in your pipeline, you can set up secrets in ",(0,i.jsx)(s.a,{href:"/engineers/pipeline-configuration-secrets",children:"pipeline configurations"}),"."]})}),"\n",(0,i.jsx)(s.h2,{id:"secret-providers",children:"Secret providers"}),"\n",(0,i.jsxs)(s.p,{children:["Each fabric can be linked to one or more providers through the ",(0,i.jsx)(s.strong,{children:"Providers"})," tab. From Prophecy, you can add, edit, or remove both providers and secrets."]}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Secret Provider"}),(0,i.jsx)(s.th,{children:"Details"}),(0,i.jsx)(s.th,{children:"Platform"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Databricks Secrets"}),(0,i.jsx)(s.td,{children:"Recommended if you are a Databricks user"}),(0,i.jsx)(s.td,{children:"Databricks"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"HashiCorp Vault"}),(0,i.jsx)(s.td,{children:"Recommended if your organization privileges HashiCorp Vault"}),(0,i.jsx)(s.td,{children:"Any Spark"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Environment Variables"}),(0,i.jsx)(s.td,{children:"Recommended if your organization privileges environment variables"}),(0,i.jsx)(s.td,{children:"Any Spark"})]})]})]}),"\n",(0,i.jsx)(s.admonition,{type:"note",children:(0,i.jsxs)(s.p,{children:["If your organization uses another system, you can fetch secrets by calling its API from a ",(0,i.jsx)(s.a,{href:"/engineers/script",children:"Script"})," gem, which runs PySpark code."]})}),"\n",(0,i.jsx)(s.h3,{id:"databricks",children:"Databricks"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.a,{href:"https://docs.databricks.com/en/security/secrets/index.html",children:"Databricks"})," is the most commonly used secret provider in Prophecy. By default, a Databricks secret provider is added to all Databricks fabrics. You can remove this if required."]}),"\n",(0,i.jsx)(s.p,{children:"If you add new secrets in Databricks, you can refresh secrets in Prophecy to fetch them. You can also add new secrets directly in Prophecy. To refresh or add secrets, you must be attached to a cluster. You can only access secrets that you also can access in Databricks."}),"\n",(0,i.jsx)(s.admonition,{title:"Free trials",type:"info",children:(0,i.jsx)(s.p,{children:"If you are using a free trial Databricks fabric, you can use Databricks as the secret provider. Your secrets will be automatically cleaned up after the trial expires. While Prophecy assigns a separate scope to each trial fabric, it is not recommended to use your production data tools for trials."})}),"\n",(0,i.jsx)(s.h3,{id:"hashicorp-vault",children:"HashiCorp Vault"}),"\n",(0,i.jsxs)(s.p,{children:["Prophecy supports ",(0,i.jsx)(s.a,{href:"https://developer.hashicorp.com/vault/docs/what-is-vault",children:"HashiCorp Vault"})," as a secret provider. When you set up HashiCorp Vault, you'll see a few additional configuration fields."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Namespace"}),": An optional field to specify the namespace within a multi-tenant Vault."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Address"}),": Auto-filled from Spark cluster. You must first set up a ",(0,i.jsx)(s.code,{children:"VAULT_ADDR"})," environment variable in the Spark cluster."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Token"}),": Auto-filled from Spark cluster. You must first set up a ",(0,i.jsx)(s.code,{children:"VAULT_TOKEN"})," environment variable in the Spark cluster."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"If you add new secrets to your vault, you can refresh secrets in Prophecy to fetch them. You can also add new secrets directly in Prophecy. To refresh or add secrets, you must be attached to a cluster. You can only access secrets that you also have access to in your Spark cluster."}),"\n",(0,i.jsx)(s.h3,{id:"environment-variables",children:"Environment variables"}),"\n",(0,i.jsx)(s.p,{children:"If you prefer a simple way to manage secrets, you can use environment variables available in your Spark cluster. To do so:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["Add a new secret provider and choose ",(0,i.jsx)(s.strong,{children:"Environment"}),"."]}),"\n",(0,i.jsx)(s.li,{children:"Add a new secret. Prophecy will automatically map this secret to an environment variable in your Spark cluster."}),"\n",(0,i.jsx)(s.li,{children:"Verify that the new environment variable exists in your Spark cluster with the correct value."}),"\n"]}),"\n",(0,i.jsx)(s.admonition,{type:"note",children:(0,i.jsx)(s.p,{children:"This method does not support refreshing or fetching secrets."})})]})}function h(e={}){const{wrapper:s}={...(0,n.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},81195:(e,s,r)=>{r.d(s,{A:()=>t});const t=r.p+"assets/images/Use_secret-a1e811f96018f92edfe2ee315b0b7fe1.png"}}]);