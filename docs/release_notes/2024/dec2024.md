---
sidebar_position: 1
id: December_2024
description: Release notes for December
title: December 2024
tags:
  - release notes
  - changelog
  - december
---

## 3.4.2.\* (December 13, 2024)

- Prophecy Python libs version: 1.9.27
- Prophecy Scala libs version: 8.6.0

### Features {#Features342}

import TOCInline from '@theme/TOCInline';

<TOCInline toc={toc}
  minHeadingLevel={4}
  maxHeadingLevel={4}
/>

#### Databricks OAuth integration

Prophecy has integrated with Databricks OAuth in order to provide you with increased security via industry-standard authentication flows.

You will see a login overlay in Prophecy, such as whe selecting a Fabric, where Databricks API interactions are required.

<img
src={require("./img/dec-data-bricks-oauth-select-fab.png").default}
alt="Select a Fabric"
width="70%"
/>

The Databricks OAuth setup must be completed by both your Databricks Account Admin and your Prophecy Team Admin.

For more information on how it works and how to set it up, see Databricks OAuth.

#### Active and Total Users APIs

You can use the Active Users and Total Users APIs to find out the number of current and total users who are logged in to Prophecy. This can help you understand usage and times of high traffic, enabling you to manage capacity more effectively.

For more information on the APIs, see Active and Total Users.

### Minor Improvements {#MinorImprovements342}

- **"Offset" column name bug fix**: We fixed a bug where naming a column using a Snowflake reserved keyword, such as "Offset", would break when using a Reformat Gem.

- **Support for null values in unit tests**: We added support for null values in unit tests. Once you upgrade your Prophecy Scala libs to 8.6.0 or later and your Prophecy Python libs to 1.9.27 or later, you should see an uncommitted diff in `prophecy/tests/*.json`. The null values will be changed to "". This won't affect anything in actual code of your Pipeline, and existing unit tests should continue working as is.

- **New Spark Fabric diagnostic error codes**: There are new diagnostic error codes for the following failures:

  - Unable to reach Databricks endpoint.
  - Unable to write execution metrics because Hive Metastore is not enabled on your Spark.
  - Authentication fails while attempting to test a Spark Fabric connection.

  For more information, see [Diagnostics](../../Spark/fabrics/diagnostics.md).
