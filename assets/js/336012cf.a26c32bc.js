"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[10461],{19232:i=>{i.exports=JSON.parse('{"label":"deployment","permalink":"/tags/deployment","allTagsPath":"/tags","count":14,"items":[{"id":"Orchestration/alternative-schedulers","title":"Alternative Schedulers","description":"Support for Alternative Orchestration Solutions","permalink":"/Orchestration/alternative-schedulers"},{"id":"Spark/fabrics/EMR-livy-installation-guide","title":"Amazon EMR","description":"This page outlines how to use Amazon EMR via Livy as your Spark execution engine in Prophecy.","permalink":"/Spark/fabrics/EMR-livy-installation-guide"},{"id":"Spark/fabrics/azure-synapse-fabric-guide","title":"Azure Synapse Analytics","description":"Configuring Synapse Fabric","permalink":"/Spark/fabrics/azure-synapse-fabric-guide"},{"id":"Spark/fabrics/dataproc/gcp-dataproc-fabric-tips","title":"Connectivity Tips","description":"If your cluster doesn\'t connect, try these tips","permalink":"/Spark/fabrics/dataproc/gcp-dataproc-fabric-tips"},{"id":"Orchestration/databricks-jobs","title":"Databricks Jobs","description":"Databricks jobs","permalink":"/Orchestration/databricks-jobs"},{"id":"Spark/fabrics/dataproc/gcp-dataproc-fabric-guide","title":"Google Cloud Dataproc","description":"Configuring GCP Dataproc Fabric","permalink":"/Spark/fabrics/dataproc/"},{"id":"architecture/self-hosted/installation-helm/install-on-aws","title":"Installation on AWS","description":"Use this guide to help when installing Prophecy on AWS.","permalink":"/architecture/self-hosted/installation-helm/install-on-aws"},{"id":"architecture/self-hosted/installation-helm/installation-helm","title":"Installation via Helm","description":"Installation via Helm","permalink":"/architecture/self-hosted/installation-helm/"},{"id":"Spark/fabrics/livy","title":"Livy","description":"Configuring Livy Fabric","permalink":"/Spark/fabrics/livy"},{"id":"Orchestration/Orchestration","title":"Orchestration","description":"Airflow and Databricks Jobs","permalink":"/Orchestration/"},{"id":"architecture/deployment/deployment","title":"Prophecy deployment","description":"Prophecy deployment is flexible and supports multiple mechanisms","permalink":"/architecture/deployment/"},{"id":"Spark/fabrics/prophecy-managed-databricks","title":"Prophecy Managed","description":"Configuring Prophecy Managed Databricks Fabric","permalink":"/Spark/fabrics/prophecy-managed-databricks"},{"id":"tutorials/Orchestration/reliable-ci-cd","title":"Reliable CI/CD with Prophecy","description":"Explore Continuous Integration and Continuous Delivery within Prophecy","permalink":"/tutorials/Orchestration/reliable-ci-cd"},{"id":"architecture/self-hosted/self-hosted","title":"Self Hosted","description":"Self Hosted","permalink":"/architecture/self-hosted/"}]}')}}]);