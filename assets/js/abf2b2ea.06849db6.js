"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[37528],{28453:(e,t,s)=>{s.d(t,{R:()=>d,x:()=>a});var n=s(96540);const r={},i=n.createContext(r);function d(e){const t=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),n.createElement(i.Provider,{value:t},e.children)}},82961:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>d,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"analysts/development/models/target-platforms/databricks-target","title":"Databricks targets","description":"Configure target models for Databricks SQL","source":"@site/docs/analysts/development/models/target-platforms/databricks-target.md","sourceDirName":"analysts/development/models/target-platforms","slug":"/engineers/databricks-target","permalink":"/engineers/databricks-target","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"model","permalink":"/tags/model"},{"inline":true,"label":"databricks","permalink":"/tags/databricks"}],"version":"current","frontMatter":{"title":"Databricks targets","id":"databricks-target","slug":"/engineers/databricks-target","description":"Configure target models for Databricks SQL","tags":["model","databricks"]},"sidebar":"mySidebar","previous":{"title":"Model sources and targets","permalink":"/engineers/model-sources-and-targets"},"next":{"title":"BigQuery targets","permalink":"/engineers/bigquery-target"}}');var r=s(74848),i=s(28453);const d={title:"Databricks targets",id:"databricks-target",slug:"/engineers/databricks-target",description:"Configure target models for Databricks SQL",tags:["model","databricks"]},a=void 0,l={},c=[{value:"Type &amp; Format",id:"type--format",level:2},{value:"Location",id:"location",level:2},{value:"Schema",id:"schema",level:2},{value:"Properties",id:"properties",level:3},{value:"SQL Query",id:"sql-query",level:2},{value:"Write Options",id:"write-options",level:2},{value:"Merge approaches",id:"merge-approaches",level:3},{value:"Specify columns",id:"specify-columns",level:4},{value:"SCD2",id:"scd2",level:4},{value:"Insert and overwrite",id:"insert-and-overwrite",level:4},{value:"Replace where",id:"replace-where",level:2},{value:"Data Tests",id:"data-tests",level:2}];function o(e){const t={a:"a",admonition:"admonition",h2:"h2",h3:"h3",h4:"h4",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.p,{children:"To configure a target model that will be written to Databricks, reference the following sections."}),"\n",(0,r.jsx)(t.h2,{id:"type--format",children:"Type & Format"}),"\n",(0,r.jsx)(t.p,{children:"Databricks supports the following materialization types for target models. The type determines the underlying physical format of your target model."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Materialization type"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"View (default)"}),(0,r.jsx)(t.td,{children:"Rebuilt as a view on each run. Views always reflect the latest source data but don\u2019t store any data themselves."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Table"}),(0,r.jsx)(t.td,{children:"Rebuilt as a table on each run. Tables are fast to query but can take longer to build. Target tables support multiple write modes."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Ephemeral"}),(0,r.jsx)(t.td,{children:"Not built in the database. The model\u2019s logic is inlined into downstream models using a common table expression (CTE). Use for lightweight transformations early in your DAG."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Materialized View"}),(0,r.jsx)(t.td,{children:"Acts like a hybrid of a view and a table. Supports use cases similar to incremental models. Creates a materialized view in the target warehouse."})]})]})]}),"\n",(0,r.jsx)(t.h2,{id:"location",children:"Location"}),"\n",(0,r.jsxs)(t.p,{children:["Review the location where your model will be written. Any changes you make to the ",(0,r.jsx)(t.strong,{children:"Overwrite location"})," section will be reflected in the ",(0,r.jsx)(t.strong,{children:"Location"})," that Prophecy generates."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Location Parameter"}),(0,r.jsx)(t.th,{children:"Description"}),(0,r.jsx)(t.th,{children:"Advanced mode"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Catalog"}),(0,r.jsx)(t.td,{children:"Catalog where the model will be created."}),(0,r.jsx)(t.td,{children:"Yes"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Schema"}),(0,r.jsx)(t.td,{children:"Schema inside the catalog where the model will be created."}),(0,r.jsx)(t.td,{children:"Yes"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Alias"}),(0,r.jsx)(t.td,{children:"Sets the name of the resulting table or view. Defaults to the model name if not specified."}),(0,r.jsx)(t.td,{children:"No"})]})]})]}),"\n",(0,r.jsx)(t.h2,{id:"schema",children:"Schema"}),"\n",(0,r.jsx)(t.p,{children:"Define the schema of the dataset and optionally configure additional properties."}),"\n",(0,r.jsx)(t.p,{children:"The schema includes column names, column data types, and optional column metadata. When you expand a row in the Schema table, you can add a column description, apply column tags, and enable/disable quoting for column names."}),"\n",(0,r.jsx)(t.h3,{id:"properties",children:"Properties"}),"\n",(0,r.jsx)(t.p,{children:"Each property maps to a certain dbt configuration that may be generic to dbt or specific to a platform like Databricks. If you do not add a property explicitly in the Schema tab, Prophecy uses the dbt default for that property."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Property"}),(0,r.jsx)(t.th,{children:"Description"}),(0,r.jsx)(t.th,{children:"Config type"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Dataset Tags"}),(0,r.jsx)(t.td,{children:"Add tags to the dataset. These tags can be used as part of the resource selection syntax in dbt."}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Contract Enforced"}),(0,r.jsxs)(t.td,{children:["Enforce a ",(0,r.jsx)(t.a,{href:"https://docs.getdbt.com/docs/mesh/govern/model-contracts",children:"contract"})," for the model schema, preventing unintended changes."]}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Show Docs"}),(0,r.jsxs)(t.td,{children:["Control whether or not nodes are shown in the ",(0,r.jsx)(t.a,{href:"https://docs.getdbt.com/docs/build/view-documentation",children:"auto-generated documentation website"}),"."]}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Enabled"}),(0,r.jsx)(t.td,{children:"Control whether the model is included in builds. When a resource is disabled, dbt will not consider it as part of your project."}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Meta"}),(0,r.jsx)(t.td,{children:"Set metadata for the table using key-value pairs."}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Group"}),(0,r.jsx)(t.td,{children:"Assign a group to the table."}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Persist Docs Columns"}),(0,r.jsx)(t.td,{children:"Save column descriptions in the database."}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Persist Docs Relations"}),(0,r.jsx)(t.td,{children:"Save model descriptions in the database."}),(0,r.jsx)(t.td,{children:"Generic"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Clustered By"}),(0,r.jsx)(t.td,{children:"Each partition in the created table will be split into a fixed number of buckets by the specified columns."}),(0,r.jsx)(t.td,{children:"Databricks"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Buckets"}),(0,r.jsxs)(t.td,{children:["The number of buckets to create while clustering. Required if ",(0,r.jsx)(t.strong,{children:"Clustered By"})," is specified."]}),(0,r.jsx)(t.td,{children:"Databricks"})]})]})]}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsxs)(t.p,{children:["For more detailed information, see the ",(0,r.jsx)(t.a,{href:"https://docs.getdbt.com/reference/references-overview",children:"dbt reference documentation"}),"."]})}),"\n",(0,r.jsx)(t.h2,{id:"sql-query",children:"SQL Query"}),"\n",(0,r.jsxs)(t.p,{children:["Add a custom SQL query at the end of your target model using the Databricks SQL dialect. This allows you to apply a final transformation step, which can be useful if you're importing an existing codebase and need to add conditions or filters to the final output. Custom queries support Jinja, dbt templating, and ",(0,r.jsx)(t.a,{href:"/engineers/data-model-configurations",children:"variable"})," usage for your last-mile data processing."]}),"\n",(0,r.jsx)(t.p,{children:"You can reference any column present in the list of input ports beside the SQL query. You can only add additional input ports\u2014the output port cannot be edited."}),"\n",(0,r.jsx)(t.h2,{id:"write-options",children:"Write Options"}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.strong,{children:"Write Options"})," tab lets you determine how you will store your processed data and handle changes to the data over time."]}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Write Mode"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Overwrite (default)"}),(0,r.jsx)(t.td,{children:"Replaces all existing data with new data on each run. The incoming table must have the same schema as the existing table."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Append"}),(0,r.jsx)(t.td,{children:"Adds new rows to the existing table. Best used when unique keys aren\u2019t required and duplicate records are acceptable. For key-based updates, use Merge instead."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Merge"}),(0,r.jsx)(t.td,{children:"Updates existing records and inserts new ones based on defined keys. Supports multiple merge strategies to handle changes accurately over time."})]})]})]}),"\n",(0,r.jsx)(t.h3,{id:"merge-approaches",children:"Merge approaches"}),"\n",(0,r.jsxs)(t.p,{children:["When you select the Merge write mode, there are multiple merge approaches to choose from. To find an example use case for each strategy, see ",(0,r.jsx)(t.a,{href:"/engineers/merge-approaches",children:"Merge approach examples"}),"."]}),"\n",(0,r.jsx)(t.h4,{id:"specify-columns",children:"Specify columns"}),"\n",(0,r.jsx)(t.p,{children:"Only update specified columns during the merge. All other columns remain unchanged."}),"\n",(0,r.jsx)("div",{class:"fixed-table",children:(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Parameter"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Unique Key"}),(0,r.jsx)(t.td,{children:"The key used to match existing records in the target dataset for merging."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Use Predicate"}),(0,r.jsx)(t.td,{children:"Lets you add conditions that specify when to apply the merge."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Use a condition to filter data or incremental runs"}),(0,r.jsx)(t.td,{children:"Enables applying conditions for filtering the incoming data into the table."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Merge Columns"}),(0,r.jsx)(t.td,{children:"Specifies which columns to update during the merge. If empty, the merge includes all columns."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Exclude Columns"}),(0,r.jsx)(t.td,{children:"Defines columns that should be excluded from the merge operation."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"On Schema Change"}),(0,r.jsxs)(t.td,{children:["Specifies how schema changes should be handled during the merge process.",(0,r.jsxs)("ul",{style:{margin:0},children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"ignore"}),": Newly added columns will not be written to the model. This is the default option."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"fail"}),": Triggers an error message when the source and target schemas diverge."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"append_new_columns"}),": Append new columns to the existing table."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"sync_all_columns"}),": Adds any new columns to the existing table, and removes any columns that are now missing. Includes data type changes. This option uses the output of the previous gem."]})]})]})]})]})]})}),"\n",(0,r.jsx)(t.h4,{id:"scd2",children:"SCD2"}),"\n",(0,r.jsx)(t.p,{children:"Tracks historical changes by adding new rows instead of updating existing ones. Each record will include additional columns containing start and end timestamps to indicate when a record was valid."}),"\n",(0,r.jsx)("div",{class:"fixed-table",children:(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Parameter"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Unique Key"}),(0,r.jsx)(t.td,{children:"The key used to match existing records in the target dataset for merging."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Invalidate deleted rows"}),(0,r.jsx)(t.td,{children:"When enabled, records that match deleted rows will be marked as no longer valid."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Determine new records by checking timestamp column"}),(0,r.jsx)(t.td,{children:"Recognizes new records by the time from the timestamp column that you define."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Determine new records by looking for differences in column values"}),(0,r.jsx)(t.td,{children:"Recognizes new records based on a change of values in one or more specified columns."})]})]})]})}),"\n",(0,r.jsx)(t.h4,{id:"insert-and-overwrite",children:"Insert and overwrite"}),"\n",(0,r.jsx)(t.p,{children:"Replace entire partitions in the target table. Only partitions including updated data will be overwritten. Other partitions will not be rebuilt."}),"\n",(0,r.jsx)("div",{class:"fixed-table",children:(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Parameter"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Partition By"}),(0,r.jsx)(t.td,{children:"Defines the partitioning column used to determine which data to replace during the merge."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"On Schema Change"}),(0,r.jsxs)(t.td,{children:["Specifies how schema changes should be handled during the merge process.",(0,r.jsxs)("ul",{style:{margin:0},children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"ignore"}),": Newly added columns will not be written to the model. This is the default option."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"fail"}),": Triggers an error message when the source and target schemas diverge."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"append_new_columns"}),": Append new columns to the existing table."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"sync_all_columns"}),": Adds any new columns to the existing table, and removes any columns that are now missing. Includes data type changes. This option uses the output of the previous gem."]})]})]})]})]})]})}),"\n",(0,r.jsxs)(t.p,{children:["If ",(0,r.jsx)(t.strong,{children:"Partition By"})," is specified, dbt runs an atomic insert overwrite statement that dynamically replaces all partitions included in your query. If no partition is specified, the strategy replaces the entire table, overriding all existing data with only the new records while maintaining the original schema."]}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsxs)(t.p,{children:["To learn more about this merge approach, see the ",(0,r.jsx)(t.a,{href:"https://docs.getdbt.com/reference/resource-configs/databricks-configs#the-insert_overwrite-strategy",children:"insert overwrite strategy"})," in the dbt documentation."]})}),"\n",(0,r.jsx)(t.h2,{id:"replace-where",children:"Replace where"}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.strong,{children:"Replace where"})," approach lets you update records that match the condition defined in the predicate."]}),"\n",(0,r.jsx)("div",{class:"fixed-table",children:(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Parameter"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Use Predicate"}),(0,r.jsx)(t.td,{children:"Lets you add conditions that specify when to apply the merge."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"Use a condition to filter data or incremental runs"}),(0,r.jsx)(t.td,{children:"Enables applying conditions for filtering the incoming data into the table."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"On Schema Change"}),(0,r.jsxs)(t.td,{children:["Specifies how schema changes should be handled during the merge process.",(0,r.jsxs)("ul",{style:{margin:0},children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"ignore"}),": Newly added columns will not be written to the model. This is the default option."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"fail"}),": Triggers an error message when the source and target schemas diverge."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"append_new_columns"}),": Append new columns to the existing table."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"sync_all_columns"}),": Adds any new columns to the existing table, and removes any columns that are now missing. Includes data type changes. This option uses the output of the previous gem."]})]})]})]})]})]})}),"\n",(0,r.jsx)(t.h2,{id:"data-tests",children:"Data Tests"}),"\n",(0,r.jsxs)(t.p,{children:["A data test is an assertion you define about a dataset in your project. Data tests are run on target models to ensure the quality and integrity of the final data that gets written to the warehouse. Learn how to build tests in ",(0,r.jsx)(t.a,{href:"/analysts/data-tests",children:"Data tests"}),"."]})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}}}]);