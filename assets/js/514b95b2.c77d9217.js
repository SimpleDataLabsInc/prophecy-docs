"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[73449],{96499:e=>{e.exports=JSON.parse('{"tag":{"label":"Execution","permalink":"/tags/execution","allTagsPath":"/tags","count":8,"items":[{"id":"Spark/execution/conditional-execution","title":"Conditional execution","description":"Conditionally run or skip transformations within Spark gems","permalink":"/engineers/conditional-execution"},{"id":"analysts/development/data-explorer/data-explorer","title":"Data exploration","description":"Generate data samples through the pipeline during development","permalink":"/analysts/data-explorer"},{"id":"Spark/data-explorer/data-explorer","title":"Data exploration","description":"Inspect interim data samples at each stage of your pipeline","permalink":"/engineers/data-explorer"},{"id":"Spark/execution/execution","title":"Execution","description":"How Prophecy computes pipelines","permalink":"/engineers/execution"},{"id":"Spark/execution/execution-metrics","title":"Execution metrics","description":"Execution Metrics","permalink":"/engineers/execution-metrics"},{"id":"getting-started/concepts/Fabric","title":"Fabrics","description":"Run pipelines in execution environments","permalink":"/fabrics"},{"id":"administration/fabrics/Spark-fabrics/Fabrics","title":"Spark fabrics","description":"Connect Prophecy to an external execution engine","permalink":"/administration/fabrics/Spark-fabrics/Fabrics"},{"id":"administration/fabrics/sql-fabrics/Fabrics","title":"SQL fabrics","description":"Perform SQL computations on a SQL warehouse","permalink":"/administration/fabrics/sql-fabrics/Fabrics"}],"unlisted":false}}')}}]);