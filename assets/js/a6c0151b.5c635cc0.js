"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[56380],{15680:(e,t,a)=>{a.d(t,{xA:()=>g,yg:()=>m});var n=a(96540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var d=n.createContext({}),s=function(e){var t=n.useContext(d),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},g=function(e){var t=s(e.components);return n.createElement(d.Provider,{value:t},e.children)},p="mdxType",y={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,d=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),p=s(a),c=r,m=p["".concat(d,".").concat(c)]||p[c]||y[c]||i;return a?n.createElement(m,l(l({ref:t},g),{},{components:a})):n.createElement(m,l({ref:t},g))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=c;var o={};for(var d in t)hasOwnProperty.call(t,d)&&(o[d]=t[d]);o.originalType=e,o[p]="string"==typeof e?e:r,l[1]=o;for(var s=2;s<i;s++)l[s]=a[s];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},32852:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>y,frontMatter:()=>i,metadata:()=>o,toc:()=>s});var n=a(58168),r=(a(96540),a(15680));const i={title:"Diagnostics",id:"fabric-diagnostics",description:"Troubleshooting fabrics using diagnostics",sidebar_position:8,tags:["diagnostics","fabric","emr","synase","dataproc"]},l=void 0,o={unversionedId:"administration/Spark-fabrics/fabric-diagnostics",id:"administration/Spark-fabrics/fabric-diagnostics",title:"Diagnostics",description:"Troubleshooting fabrics using diagnostics",source:"@site/docs/administration/Spark-fabrics/diagnostics.md",sourceDirName:"administration/Spark-fabrics",slug:"/administration/Spark-fabrics/fabric-diagnostics",permalink:"/administration/Spark-fabrics/fabric-diagnostics",draft:!1,tags:[{label:"diagnostics",permalink:"/tags/diagnostics"},{label:"fabric",permalink:"/tags/fabric"},{label:"emr",permalink:"/tags/emr"},{label:"synase",permalink:"/tags/synase"},{label:"dataproc",permalink:"/tags/dataproc"}],version:"current",sidebarPosition:8,frontMatter:{title:"Diagnostics",id:"fabric-diagnostics",description:"Troubleshooting fabrics using diagnostics",sidebar_position:8,tags:["diagnostics","fabric","emr","synase","dataproc"]},sidebar:"adminSidebar",previous:{title:"Connectivity Tips",permalink:"/administration/Spark-fabrics/dataproc/gcp-dataproc-fabric-tips"},next:{title:"Set up Spark fabrics",permalink:"/administration/Spark-fabrics/Fabrics"}},d={},s=[{value:"Diagnostics error codes",id:"diagnostics-error-codes",level:2}],g={toc:s},p="wrapper";function y(e){let{components:t,...a}=e;return(0,r.yg)(p,(0,n.A)({},g,a,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"Troubleshooting Prophecy fabrics is much easier with built-in diagnostics. The descriptions are designed to help users to independently identify and resolve issues. When creating or connecting to a fabric, Prophecy automatically tests for connectivity. This feature helps users to determine whether the issue lies within Prophecy itself or in other components of the data ecosystem."),(0,r.yg)("h2",{id:"diagnostics-error-codes"},"Diagnostics error codes"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Error Code"),(0,r.yg)("th",{parentName:"tr",align:null},"Symptom"),(0,r.yg)("th",{parentName:"tr",align:null},"Provider"),(0,r.yg)("th",{parentName:"tr",align:null},"Cause"),(0,r.yg)("th",{parentName:"tr",align:null},"Resolution"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10000")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"Is missing from the classpath")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/databricks/"},"Databricks")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Scala) is incorrect. You're probably using thin jar."),(0,r.yg)("td",{parentName:"tr",align:null},"Use assembly ",(0,r.yg)("inlineCode",{parentName:"td"},"jar(${scalaFatJarName})")," in the library section of the fabric settings.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10001")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"DRIVER_LIBRARY_INSTALLATION_FAILURE")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/databricks/"},"Databricks")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Scala/Python) is incorrect. Databricks could not install it."),(0,r.yg)("td",{parentName:"tr",align:null},"Please provide the valid library path in the fabric.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10002")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"object prophecy is not a member of package")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Scala) is incorrect."),(0,r.yg)("td",{parentName:"tr",align:null},"Please ensure that the library path exists and you\u2019re using the assembly ",(0,r.yg)("inlineCode",{parentName:"td"},"jar(${scalaFatJarName})"),".")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10003")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"cannot be added to user sessions")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"prophecy_libs")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Python) is incorrect."),(0,r.yg)("td",{parentName:"tr",align:null},"Please ensure that the library path exists and you\u2019re using correct ",(0,r.yg)("inlineCode",{parentName:"td"},"file(${pythonPLibName})"),".")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10004")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"for method")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"too many arguments")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Scala) is incompatible."),(0,r.yg)("td",{parentName:"tr",align:null},"Please use the correct ",(0,r.yg)("inlineCode",{parentName:"td"},"version(${Globals.prophecyLibsVersion})")," in the library section of fabric settings.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10005")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"No module named")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"prophecy")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Python) is incorrect."),(0,r.yg)("td",{parentName:"tr",align:null},"Please provide the valid library path in the fabric.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10006")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"illegal start of simple expression")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Python version in livy/hadoop is incorrect."),(0,r.yg)("td",{parentName:"tr",align:null},"Please make sure you have python3 there.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10007")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"IncompatibleClassChangeError")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Scala) is incompatible with your Spark version."),(0,r.yg)("td",{parentName:"tr",align:null},"Please use the correct assembly ",(0,r.yg)("inlineCode",{parentName:"td"},"jar(${scalaFatJarName})")," in the library section of the fabric settings.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10008")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},'"FileNotFoundException')," and ",(0,r.yg)("inlineCode",{parentName:"td"},'prophecy_libs"')),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Prophecy Library(Python) path does not exist."),(0,r.yg)("td",{parentName:"tr",align:null},"Please ensure that the file exists as per the path in the library section of the fabric settings.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10009")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"503 Service Temporarily Unavailable")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"LivyRestClient")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"https://livy.apache.org/docs/latest/rest-api.html"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Livy service is down."),(0,r.yg)("td",{parentName:"tr",align:null},"Please make sure the livy service is up before executing this command.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10010")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"SQLNonTransientConnectionException, rds.amazonaws.com")," or ",(0,r.yg)("inlineCode",{parentName:"td"},"Unable to instantiate, HiveMetaStoreClient")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"https://docs.databricks.com/en/resources/supported-regions.html#rds"},"Unity Catalog")),(0,r.yg)("td",{parentName:"tr",align:null},"Databricks cluster can't access RDS service."),(0,r.yg)("td",{parentName:"tr",align:null},"Please ensure that the cluster can access to the same region's RDS endpoint as documented ",(0,r.yg)("a",{parentName:"td",href:"https://docs.databricks.com/en/resources/supported-regions.html#rds"},"here"),".")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10011")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"UnauthorizedCommandException")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"This execution contained at leas")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"disallowed language")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/concepts/project/"},"Unity Catalog")),(0,r.yg)("td",{parentName:"tr",align:null},"Shared cluster in unity catalog does not allow Scala commands."),(0,r.yg)("td",{parentName:"tr",align:null},"Please use this cluster with Python Pipeline.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10012")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"UnauthorizedCommandException")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"This execution contained at leas")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"disallowed language")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"https://docs.databricks.com/en/administration-guide/users-groups/index.html"},"Databricks")),(0,r.yg)("td",{parentName:"tr",align:null},"This cluster does not allow ",(0,r.yg)("inlineCode",{parentName:"td"},"${pipeline's language}")," command."),(0,r.yg)("td",{parentName:"tr",align:null},"Please check with the Databricks workspace administrator to provide the execution access to ",(0,r.yg)("inlineCode",{parentName:"td"},"${pipeline's language}")," language.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10013")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"javax.net.ssl.SSLHandshakeException")," and ",(0,r.yg)("inlineCode",{parentName:"td"},"PKIX path building failed")),(0,r.yg)("td",{parentName:"tr",align:null},"Livy / ",(0,r.yg)("a",{parentName:"td",href:"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-security.html"},"EMR")),(0,r.yg)("td",{parentName:"tr",align:null},"Certificates provided in EMR cluster's security configuration are wrong."),(0,r.yg)("td",{parentName:"tr",align:null},"Please ensure that EMR cluster's security configuration is using correct certificates.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10014")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"HostUnreachableErrorCode_10014")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"https://docs.databricks.com/en/administration-guide/users-groups/index.html"},"Databricks")),(0,r.yg)("td",{parentName:"tr",align:null},"Unable to reach Databricks endpoint."),(0,r.yg)("td",{parentName:"tr",align:null},"Make sure the workspace is active and reachable.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10015")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"HiveMetastoreNotEnabledErrorCode_10015")),(0,r.yg)("td",{parentName:"tr",align:null},"Hive Metastore"),(0,r.yg)("td",{parentName:"tr",align:null},"We were unable to write execution metrics because Hive Metastore is not enabled on your Spark."),(0,r.yg)("td",{parentName:"tr",align:null},"Please enable Hive Metastore on Spark, or disable execution metrics in Prophecy.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10016")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"AuthenticationFAiled_10016")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("a",{parentName:"td",href:"/administration/Spark-fabrics/livy"},"Livy")),(0,r.yg)("td",{parentName:"tr",align:null},"Authentication failed. Wrong or no auth credentials were provided."),(0,r.yg)("td",{parentName:"tr",align:null},"Make sure correct auth credentials are provided.")))))}y.isMDXComponent=!0}}]);