"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[9571],{3905:(e,t,o)=>{o.d(t,{Zo:()=>p,kt:()=>f});var r=o(67294);function n(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function a(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,r)}return o}function s(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?a(Object(o),!0).forEach((function(t){n(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):a(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function i(e,t){if(null==e)return{};var o,r,n=function(e,t){if(null==e)return{};var o,r,n={},a=Object.keys(e);for(r=0;r<a.length;r++)o=a[r],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)o=a[r],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var c=r.createContext({}),l=function(e){var t=r.useContext(c),o=t;return e&&(o="function"==typeof e?e(t):s(s({},t),e)),o},p=function(e){var t=l(e.components);return r.createElement(c.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},b=r.forwardRef((function(e,t){var o=e.components,n=e.mdxType,a=e.originalType,c=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=l(o),b=n,f=u["".concat(c,".").concat(b)]||u[b]||d[b]||a;return o?r.createElement(f,s(s({ref:t},p),{},{components:o})):r.createElement(f,s({ref:t},p))}));function f(e,t){var o=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var a=o.length,s=new Array(a);s[0]=b;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i[u]="string"==typeof e?e:n,s[1]=i;for(var l=2;l<a;l++)s[l]=o[l];return r.createElement.apply(null,s)}return r.createElement.apply(null,o)}b.displayName="MDXCreateElement"},61105:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>l});var r=o(83117),n=(o(67294),o(3905));const a={title:"Low-code Jobs",id:"low-code-jobs",description:"Low-code Jobs",tags:["jobs","deployment","scheduling"]},s=void 0,i={unversionedId:"low-code-jobs/low-code-jobs",id:"low-code-jobs/low-code-jobs",title:"Low-code Jobs",description:"Low-code Jobs",source:"@site/docs/low-code-jobs/low-code-jobs.md",sourceDirName:"low-code-jobs",slug:"/low-code-jobs/",permalink:"/low-code-jobs/",draft:!1,tags:[{label:"jobs",permalink:"/tags/jobs"},{label:"deployment",permalink:"/tags/deployment"},{label:"scheduling",permalink:"/tags/scheduling"}],version:"current",frontMatter:{title:"Low-code Jobs",id:"low-code-jobs",description:"Low-code Jobs",tags:["jobs","deployment","scheduling"]},sidebar:"defaultSidebar",previous:{title:"Execution on Databricks",permalink:"/low-code-spark/execution/executions_on_databricks_clusters"},next:{title:"Databricks Jobs",permalink:"/low-code-jobs/databricks-jobs"}},c={},l=[],p={toc:l},u="wrapper";function d(e){let{components:t,...o}=e;return(0,n.kt)(u,(0,r.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"Once you have developed a Spark data Pipeline using Prophecy, you will want to schedule it to run at some frequency. To\nsupport this, Prophecy provides you with an easy to use low-code interface to develop Jobs, using two different\nschedulers:"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("a",{parentName:"strong",href:"/low-code-jobs/databricks-jobs"},"Databricks Jobs"))," - for simpler data-Pipeline use-cases, where you just\norchestrate multiple data-Pipelines to run together. Databricks Jobs is a ",(0,n.kt)("strong",{parentName:"p"},"recommended")," scheduler, if you're\nDatabricks Native.")),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("a",{parentName:"strong",href:"/low-code-jobs/airflow"},"Airflow"))," - for more complex use-cases, where you have to use various operators, or need\nany additional data pre-and-post-processing, you can design your Jobs using Prophecy's low-code Airflow environment."))),(0,n.kt)("p",null,"Alternatively, since Prophecy provides you native Spark code on Git, you can easily integrate with any other scheduler."))}d.isMDXComponent=!0}}]);