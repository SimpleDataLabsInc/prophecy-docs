"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[8969],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return h}});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(a),h=r,m=u["".concat(l,".").concat(h)]||u[h]||d[h]||i;return a?n.createElement(m,o(o({ref:t},c),{},{components:a})):n.createElement(m,o({ref:t},c))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},92349:function(e,t,a){a.r(t),a.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return h},frontMatter:function(){return s},metadata:function(){return p},toc:function(){return d}});var n=a(87462),r=a(63366),i=(a(67294),a(3905)),o=["components"],s={title:"Design a Pipeline",id:"design-pipeline",description:"How to design your first Pipeline",sidebar_position:2,tags:["Pipelines","tutorial"]},l=void 0,p={unversionedId:"tutorials/videos/design-pipeline",id:"tutorials/videos/design-pipeline",title:"Design a Pipeline",description:"How to design your first Pipeline",source:"@site/docs/tutorials/videos/design-pipeline.md",sourceDirName:"tutorials/videos",slug:"/tutorials/videos/design-pipeline",permalink:"/tutorials/videos/design-pipeline",draft:!1,tags:[{label:"Pipelines",permalink:"/tags/pipelines"},{label:"tutorial",permalink:"/tags/tutorial"}],version:"current",sidebarPosition:2,frontMatter:{title:"Design a Pipeline",id:"design-pipeline",description:"How to design your first Pipeline",sidebar_position:2,tags:["Pipelines","tutorial"]},sidebar:"defaultSidebar",previous:{title:"Video Tutorials",permalink:"/category/video-tutorials"}},c={},d=[{value:"Summary",id:"summary",level:3},{value:"Description",id:"description",level:3},{value:"Transcript",id:"transcript",level:3},{value:"Follow along checklist",id:"follow-along-checklist",level:3}],u={toc:d};function h(e){var t=e.components,a=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("div",{class:"wistia_responsive_padding",style:{padding:"56.25% 0 0 0",position:"relative"}},(0,i.kt)("div",{class:"wistia_responsive_wrapper",style:{height:"100%",left:0,position:"absolute",top:0,width:"100%"}},(0,i.kt)("iframe",{src:"https://fast.wistia.net/embed/iframe/i61o34x245?seo=false?videoFoam=true",title:"Design a Pipeline Video",allow:"autoplay; fullscreen",allowtransparency:"true",frameborder:"0",scrolling:"no",class:"wistia_embed",name:"wistia_embed",msallowfullscreen:!0,width:"100%",height:"100%"}))),(0,i.kt)("script",{src:"https://fast.wistia.net/assets/external/E-v1.js",async:!0}),(0,i.kt)("h3",{id:"summary"},"Summary"),(0,i.kt)("p",null,"Design a data transformation Pipeline and generate a report - all using a low-code interface for Apache Spark."),(0,i.kt)("h3",{id:"description"},"Description"),(0,i.kt)("p",null,"Using a low-code interface, ingest a shipments Dataset and create a pricing summary report. Read and write from multiple data sources, including Snowflake and Delta Catalog Table. Run the Pipeline interactively and see the Job in Databricks. View the generated code - either Python or Scala - which runs on Apache Spark. In the next trainings, we'll see how to commit this code to Git, version our changes, schedule, and test our Pipeline."),(0,i.kt)("h3",{id:"transcript"},"Transcript"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=0s"},"Connect to Git"),(0,i.kt)("br",{parentName:"p"}),"\n","Let\u2019s get started on Prophecy for Databricks. After logging into Prophecy, create a project called Reporting. All the Pipelines that you\u2019re going to build are turned into high quality code. Here you can choose the programming language of that code - either Python or Scala."),(0,i.kt)("p",null,"Prophecy will store all of that code in repositories on Git. Git enables you to version all of your changes, collaborate easily with your team, and track exactly what code is deployed to production. You can connect to one of your existing Git repositories. If you don\u2019t have one, Prophecy can create one for you."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=53s"},"Create Pipeline"),(0,i.kt)("br",{parentName:"p"}),"\n","As part of our Reporting project, let\u2019s create our pricingReport Pipeline. Connect to a Spark Cluster. With one click, we can see our Spark cluster running in Databricks."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=80s"},"Overview and Define Source Data"),(0,i.kt)("br",{parentName:"p"}),"\n","Coming back to the Prophecy UI; we\u2019re going to build a Pipeline to report the amount of business that was billed, shipped, and returned. With Prophecy I can read and write to any data source. We\u2019re going to read from Snowflake. I store my credentials as Databricks secrets. Read from the ordershipments table. This table contains information about each order, whether the order was billed, shipped, or returned. We can see the schema right away. Load a data preview - the data looks as expected. Each record is an item to be shipped. We\u2019ll use the columns relating to price and shipping status."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=140s"},"Choose Transformations"),(0,i.kt)("br",{parentName:"p"}),"\n","Let\u2019s start to design our Pipeline by choosing some transformations; a Reformat Gem to Cleanup the Data, an Aggregate Gem to Sum the Amounts,an OrderBy Gem to OrderBy Shipment Status, then a Target Gem to write the Report to a Catalog table."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=169s"},"Build Custom Expressions"),(0,i.kt)("br",{parentName:"p"}),"\n","Configure each transformation. Select the columns of interest for our pricing report. Create some expressions to cleanup the Dataset. If the Tax is null, specify a default tax rate. Let\u2019s also create a column to capture a business rule: a 'case when' statement marking an item as clearance."),(0,i.kt)("p",null,"Configure the aggregate expressions. Start with basic SQL functions, and Prophecy will help you build expressions. Later Prophecy will convert these SparkSQL expressions into Python or Scala. Compute a sum of prices, discounts, and tax. Count the orders and whether the item was marked Clearance. Group-by whether the item was returned, and whether the item was delivered."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=238s"},"Interactive Execution"),(0,i.kt)("br",{parentName:"p"}),"\n","Run the Pipeline upto the sumAmounts Gem. Organize the Gems on the canvas. Let\u2019s see what we\u2019ve got so far. We can see the interim sample data output from each Gem. Data types are correct. We can see the summed amounts and orders, the returned or delivery statuses, and how many of these orders were marked clearance. We can see some basic statistics for each column. Configure the OrderBy Gem. We want to know if the item was returned and/or delivered."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=291s"},"Write to Delta Catalog Table"),(0,i.kt)("br",{parentName:"p"}),"\n","Configure the target Dataset. We\u2019ll choose to write to a Delta Catalog table. Specify the details and some properties. Here we\u2019ll overwrite the table schema, but there are lots of options. Run the Pipeline one final time to write the report to a Catalog table."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=326s"},"Toggle to View Code"),(0,i.kt)("br",{parentName:"p"}),"\n","We designed our Pipeline! Let\u2019s see what the code looks like behind the scenes. Here is the graph representation, each function represents a Gem; the shipments Dataset, the cleanup function, the sumAmounts function. See the Cleanup function code; this is what you write as a highly skilled data engineer."),(0,i.kt)("p",null,"Great!\nIn the next few trainings, we\u2019ll see how to commit our code to Git, version our changes, schedule and test our Pipeline."),(0,i.kt)("p",null,"See you next time!"),(0,i.kt)("h3",{id:"follow-along-checklist"},"Follow along checklist"),(0,i.kt)("p",null,"Create a repository."),(0,i.kt)("p",null,"Snowflake and Databricks credentials are used here, but you can read/write to the data source(s) to which you have credentials. Setup ",(0,i.kt)("a",{parentName:"p",href:"https://docs.databricks.com/security/secrets/secrets.html#create-a-secret-in-a-databricks-backed-scope"},"Databricks Secrets")," to avoid exposing secrets when the project is committed to Git."),(0,i.kt)("p",null,"Set Prophecy credentials while signing up for a free trial here: ",(0,i.kt)("a",{parentName:"p",href:"https://App.Prophecy.io/"},"App.Prophecy.io")),(0,i.kt)("p",null,"The Shipments Dataset is actually a table called ORDERSHIPMENTS in the TPC-H Dataset, and is available as sample data in Snowflake, Databricks File System, and many other data sources. The column names were edited for clarity."),(0,i.kt)("p",null,"Go for it! Follow the steps outlined in the ",(0,i.kt)("a",{parentName:"p",href:"https://fast.wistia.net/embed/channel/s98lbj0pfs?wchannelid=s98lbj0pfs&wvideoid=i61o34x245&wtime=0s"},"video"),"; ask questions on Prophecy's ",(0,i.kt)("a",{parentName:"p",href:"https://join.slack.com/t/prophecy-io-support/shared_invite/zt-moq3xzoj-~5MSJ6WPnZfz7bwsqWi8tQ"},"Slack")))}h.isMDXComponent=!0}}]);