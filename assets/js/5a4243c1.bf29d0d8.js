"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[1533],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>k});var r=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},l=Object.keys(e);for(r=0;r<l.length;r++)a=l[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)a=l[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),p=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,l=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),m=p(a),c=n,k=m["".concat(s,".").concat(c)]||m[c]||u[c]||l;return a?r.createElement(k,i(i({ref:t},d),{},{components:a})):r.createElement(k,i({ref:t},d))}));function k(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var l=a.length,i=new Array(l);i[0]=c;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[m]="string"==typeof e?e:n,i[1]=o;for(var p=2;p<l;p++)i[p]=a[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}c.displayName="MDXCreateElement"},72360:(e,t,a)=>{a.d(t,{Z:()=>i});var r=a(67294),n=a(86010);const l={tabItem:"tabItem_OmH5"};function i(e){let{children:t,hidden:a,className:i}=e;return r.createElement("div",{role:"tabpanel",className:(0,n.Z)(l.tabItem,i),hidden:a},t)}},9877:(e,t,a)=>{a.d(t,{Z:()=>u});var r=a(83117),n=a(67294),l=a(72389),i=a(67392),o=a(7094),s=a(12466),p=a(86010);const d={tabList:"tabList_uSqn",tabItem:"tabItem_LplD"};function m(e){const{lazy:t,block:a,defaultValue:l,values:m,groupId:u,className:c}=e,k=n.Children.map(e.children,(e=>{if((0,n.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})),g=m??k.map((e=>{let{props:{value:t,label:a,attributes:r}}=e;return{value:t,label:a,attributes:r}})),f=(0,i.l)(g,((e,t)=>e.value===t.value));if(f.length>0)throw new Error(`Docusaurus error: Duplicate values "${f.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`);const b=null===l?l:l??k.find((e=>e.props.default))?.props.value??k[0]?.props.value;if(null!==b&&!g.some((e=>e.value===b)))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${b}" but none of its children has the corresponding value. Available values are: ${g.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);const{tabGroupChoices:h,setTabGroupChoices:N}=(0,o.U)(),[v,y]=(0,n.useState)(b),w=[],{blockElementScrollPositionUntilNextRender:T}=(0,s.o5)();if(null!=u){const e=h[u];null!=e&&e!==v&&g.some((t=>t.value===e))&&y(e)}const C=e=>{const t=e.currentTarget,a=w.indexOf(t),r=g[a].value;r!==v&&(T(t),y(r),null!=u&&N(u,r))},q=e=>{let t=null;switch(e.key){case"ArrowRight":{const a=w.indexOf(e.currentTarget)+1;t=w[a]||w[0];break}case"ArrowLeft":{const a=w.indexOf(e.currentTarget)-1;t=w[a]||w[w.length-1];break}}t?.focus()};return n.createElement("div",{className:(0,p.Z)("tabs-container",d.tabList)},n.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,p.Z)("tabs",{"tabs--block":a},c)},g.map((e=>{let{value:t,label:a,attributes:l}=e;return n.createElement("li",(0,r.Z)({role:"tab",tabIndex:v===t?0:-1,"aria-selected":v===t,key:t,ref:e=>w.push(e),onKeyDown:q,onFocus:C,onClick:C},l,{className:(0,p.Z)("tabs__item",d.tabItem,l?.className,{"tabs__item--active":v===t})}),a??t)}))),t?(0,n.cloneElement)(k.filter((e=>e.props.value===v))[0],{className:"margin-top--md"}):n.createElement("div",{className:"margin-top--md"},k.map(((e,t)=>(0,n.cloneElement)(e,{key:t,hidden:e.props.value!==v})))))}function u(e){const t=(0,l.Z)();return n.createElement(m,(0,r.Z)({key:String(t)},e))}},51335:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>s,default:()=>k,frontMatter:()=>o,metadata:()=>p,toc:()=>m});var r=a(83117),n=(a(67294),a(3905)),l=a(9877),i=a(72360);const o={title:"Parquet",id:"parquet",description:"Parquet",sidebar_position:2,tags:["gems","file","parquet"]},s=void 0,p={unversionedId:"low-code-spark/gems/source-target/file/parquet",id:"low-code-spark/gems/source-target/file/parquet",title:"Parquet",description:"Parquet",source:"@site/docs/low-code-spark/gems/source-target/file/parquet.md",sourceDirName:"low-code-spark/gems/source-target/file",slug:"/low-code-spark/gems/source-target/file/parquet",permalink:"/low-code-spark/gems/source-target/file/parquet",draft:!1,tags:[{label:"gems",permalink:"/tags/gems"},{label:"file",permalink:"/tags/file"},{label:"parquet",permalink:"/tags/parquet"}],version:"current",sidebarPosition:2,frontMatter:{title:"Parquet",id:"parquet",description:"Parquet",sidebar_position:2,tags:["gems","file","parquet"]},sidebar:"defaultSidebar",previous:{title:"FTP",permalink:"/low-code-spark/gems/source-target/file/ftp"},next:{title:"Avro",permalink:"/low-code-spark/gems/source-target/file/avro"}},d={},m=[{value:"Source",id:"source",level:2},{value:"Source Parameters",id:"source-parameters",level:3},{value:"Example",id:"source-example",level:3},{value:"Generated Code",id:"source-code",level:3},{value:"Target",id:"target",level:2},{value:"Target Parameters",id:"target-parameters",level:3},{value:"Supported Write Modes",id:"supported-write-modes",level:3},{value:"Example",id:"target",level:3},{value:"Generated Code",id:"target-code",level:3}],u={toc:m},c="wrapper";function k(e){let{components:t,...a}=e;return(0,n.kt)(c,(0,r.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"Parquet is an open-source Columnar storage data format. It handles large volumes of data by supporting complex pushdown predicates, nested schemas and a wide variety of column encoding types."),(0,n.kt)("p",null,"This Gem allows you to read from or write to Parquet files."),(0,n.kt)("h2",{id:"source"},"Source"),(0,n.kt)("p",null,"Reads data from Parquet files at the given path."),(0,n.kt)("h3",{id:"source-parameters"},"Source Parameters"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,n.kt)("th",{parentName:"tr",align:null},"Description"),(0,n.kt)("th",{parentName:"tr",align:null},"Required"),(0,n.kt)("th",{parentName:"tr",align:null},"Default"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Location"),(0,n.kt)("td",{parentName:"tr",align:null},"File path where parquet files are present"),(0,n.kt)("td",{parentName:"tr",align:null},"True"),(0,n.kt)("td",{parentName:"tr",align:null},"None")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Schema"),(0,n.kt)("td",{parentName:"tr",align:null},"Schema to be applied on the loaded data. Can be defined/edited as json or inferred using ",(0,n.kt)("inlineCode",{parentName:"td"},"Infer Schema")," button"),(0,n.kt)("td",{parentName:"tr",align:null},"True"),(0,n.kt)("td",{parentName:"tr",align:null},"None")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Recursive File Lookup"),(0,n.kt)("td",{parentName:"tr",align:null},"This is used to recursively load files from the given Location. Disables partition discovery. An exception will be thrown if this option and a ",(0,n.kt)("inlineCode",{parentName:"td"},"partitionSpec")," are specified."),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"False")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Path Global Filter"),(0,n.kt)("td",{parentName:"tr",align:null},"An optional glob pattern to only include files with paths matching the pattern. The syntax follows ",(0,n.kt)("a",{parentName:"td",href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/fs/GlobFilter.html"},"GlobFilter"),". It does not change the behavior of partition discovery."),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"None")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Modified Before"),(0,n.kt)("td",{parentName:"tr",align:null},"An optional Timestamp to only include files with modification times occurring before the specified Time. The provided timestamp must be in ",(0,n.kt)("inlineCode",{parentName:"td"},"YYYY-MM-DDTHH:mm:ss")," form (e.g. ",(0,n.kt)("inlineCode",{parentName:"td"},"2020-06-01T13:00:00"),")"),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"None")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Modified After"),(0,n.kt)("td",{parentName:"tr",align:null},"An optional timestamp to only include files with modification times occurring after the specified Time. The provided timestamp must be in ",(0,n.kt)("inlineCode",{parentName:"td"},"YYYY-MM-DDTHH:mm:ss")," form (e.g. ",(0,n.kt)("inlineCode",{parentName:"td"},"2020-06-01T13:00:00"),")"),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"None")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Merge Schema"),(0,n.kt)("td",{parentName:"tr",align:null},"Sets whether schemas should be merged from all collected Parquet part-files. This will override ",(0,n.kt)("inlineCode",{parentName:"td"},"spark.sql.parquet.mergeSchema"),"."),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"(value of ",(0,n.kt)("inlineCode",{parentName:"td"},"spark.sql.parquet."),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"mergeSchema"),")")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Int96 Rebase mode"),(0,n.kt)("td",{parentName:"tr",align:null},"The ",(0,n.kt)("inlineCode",{parentName:"td"},"int96RebaseMode")," option allows to specify the rebasing mode for INT96 timestamps from the Julian to Proleptic Gregorian calendar. ",(0,n.kt)("br",null),(0,n.kt)("br",null)," Currently supported modes are: ",(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"EXCEPTION"),": fails in reads of ancient INT96 timestamps that are ambiguous between the two calendars.",(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"CORRECTED"),": loads INT96 timestamps without rebasing.",(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"LEGACY"),": performs rebasing of ancient timestamps from the Julian to Proleptic Gregorian calendar."),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"(value of ",(0,n.kt)("inlineCode",{parentName:"td"},"spark.sql.parquet"),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},".int96RebaseModeInRead"),")")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Datetime Rebase mode"),(0,n.kt)("td",{parentName:"tr",align:null},"The ",(0,n.kt)("inlineCode",{parentName:"td"},"datetimeRebaseMode")," option allows to specify the rebasing mode for the values of the DATE, TIMESTAMP_MILLIS, TIMESTAMP_MICROS logical types from the Julian to Proleptic Gregorian calendar.",(0,n.kt)("br",null),"Currently supported modes are:",(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"EXCEPTION"),": fails in reads of ancient dates/timestamps that are ambiguous between the two calendars.",(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"CORRECTED"),": loads dates/timestamps without rebasing.",(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},"LEGACY"),": performs rebasing of ancient dates/timestamps from the Julian to Proleptic Gregorian calendar."),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"(value of ",(0,n.kt)("inlineCode",{parentName:"td"},"spark.sql.parquet"),(0,n.kt)("br",null),(0,n.kt)("inlineCode",{parentName:"td"},".datetimeRebaseModeInRead"),")")))),(0,n.kt)("h3",{id:"source-example"},"Example"),(0,n.kt)("div",{class:"wistia_responsive_padding",style:{padding:"56.25% 0 0 0",position:"relative"}},(0,n.kt)("div",{class:"wistia_responsive_wrapper",style:{height:"100%",left:0,position:"absolute",top:0,width:"100%"}},(0,n.kt)("iframe",{src:"https://user-images.githubusercontent.com/103921419/175030738-4c53b5c9-73e7-46c7-9fdc-c49048f78572.mp4",title:"Parquet Source",allow:"autoplay;fullscreen",allowtransparency:"true",frameborder:"0",scrolling:"no",class:"wistia_embed",name:"wistia_embed",msallowfullscreen:!0,width:"100%",height:"100%"}))),(0,n.kt)("h3",{id:"source-code"},"Generated Code"),(0,n.kt)(l.Z,{mdxType:"Tabs"},(0,n.kt)(i.Z,{value:"py",label:"Python",mdxType:"TabItem"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-py"},'def read_parquet(spark: SparkSession) -> DataFrame:\n    return spark.read\\\n        .format("parquet")\\\n        .option("mergeSchema", True)\\\n        .load("dbfs:/FileStore/Users/parquet/test.parquet")\n\n'))),(0,n.kt)(i.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-scala"},'object read_parquet {\n\n  def apply(spark: SparkSession): DataFrame =\n    spark.read\n        .format("parquet")\n        .option("mergeSchema", true)\n        .load("dbfs:/FileStore/Users/parquet/test.parquet")\n\n}\n')))),(0,n.kt)("hr",null),(0,n.kt)("h2",{id:"target"},"Target"),(0,n.kt)("h3",{id:"target-parameters"},"Target Parameters"),(0,n.kt)("p",null,"Write data as Parquet files at the specified path."),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,n.kt)("th",{parentName:"tr",align:null},"Description"),(0,n.kt)("th",{parentName:"tr",align:null},"Required"),(0,n.kt)("th",{parentName:"tr",align:null},"Default"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Location"),(0,n.kt)("td",{parentName:"tr",align:null},"File path where the Parquet files will be written"),(0,n.kt)("td",{parentName:"tr",align:null},"True"),(0,n.kt)("td",{parentName:"tr",align:null},"None")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Compression"),(0,n.kt)("td",{parentName:"tr",align:null},"Compression codec to use when saving to file. This can be one of the known case-insensitive shorten names (",(0,n.kt)("inlineCode",{parentName:"td"},"none"),", ",(0,n.kt)("inlineCode",{parentName:"td"},"uncompressed"),", ",(0,n.kt)("inlineCode",{parentName:"td"},"snappy"),", ",(0,n.kt)("inlineCode",{parentName:"td"},"gzip"),", ",(0,n.kt)("inlineCode",{parentName:"td"},"lzo"),", ",(0,n.kt)("inlineCode",{parentName:"td"},"brotli"),", ",(0,n.kt)("inlineCode",{parentName:"td"},"lz4"),", and ",(0,n.kt)("inlineCode",{parentName:"td"},"zstd"),"). This will override ",(0,n.kt)("inlineCode",{parentName:"td"},"spark.sql.parquet.compression.codec"),"."),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"`snappy")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Write Mode"),(0,n.kt)("td",{parentName:"tr",align:null},"How to handle existing data. See ",(0,n.kt)("a",{parentName:"td",href:"#supported-write-modes"},"this table")," for a list of available options."),(0,n.kt)("td",{parentName:"tr",align:null},"True"),(0,n.kt)("td",{parentName:"tr",align:null},(0,n.kt)("inlineCode",{parentName:"td"},"error"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Partition Columns"),(0,n.kt)("td",{parentName:"tr",align:null},"List of columns to partition the Parquet files by"),(0,n.kt)("td",{parentName:"tr",align:null},"False"),(0,n.kt)("td",{parentName:"tr",align:null},"None")))),(0,n.kt)("h3",{id:"supported-write-modes"},"Supported Write Modes"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Write Mode"),(0,n.kt)("th",{parentName:"tr",align:null},"Description"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"overwrite"),(0,n.kt)("td",{parentName:"tr",align:null},"If data already exists, overwrite with the contents of the Dataframe")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"append"),(0,n.kt)("td",{parentName:"tr",align:null},"If data already exists, append the contents of the Dataframe")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"ignore"),(0,n.kt)("td",{parentName:"tr",align:null},"If data already exists, do nothing with the contents of the Dataframe. This is similar to a ",(0,n.kt)("inlineCode",{parentName:"td"},"CREATE TABLE IF NOT EXISTS")," in SQL.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"error"),(0,n.kt)("td",{parentName:"tr",align:null},"If data already exists, throw an exception.")))),(0,n.kt)("h3",{id:"target"},"Example"),(0,n.kt)("div",{class:"wistia_responsive_padding",style:{padding:"56.25% 0 0 0",position:"relative"}},(0,n.kt)("div",{class:"wistia_responsive_wrapper",style:{height:"100%",left:0,position:"absolute",top:0,width:"100%"}},(0,n.kt)("iframe",{src:"https://user-images.githubusercontent.com/103921419/175030713-9de9d38a-c145-42e9-8411-baa44a70d0d0.mp4",title:"Parquet Target",allow:"autoplay;fullscreen",allowtransparency:"true",frameborder:"0",scrolling:"no",class:"wistia_embed",name:"wistia_embed",msallowfullscreen:!0,width:"100%",height:"100%"}))),(0,n.kt)("h3",{id:"target-code"},"Generated Code"),(0,n.kt)(l.Z,{mdxType:"Tabs"},(0,n.kt)(i.Z,{value:"py",label:"Python",mdxType:"TabItem"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-py"},'def write_parquet(spark: SparkSession, in0: DataFrame):\n    in0.write\\\n        .format("parquet")\\\n        .mode("overwrite")\\\n        .save("dbfs:/data/test_output.parquet")\n'))),(0,n.kt)(i.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-scala"},'object write_parquet {\n  def apply(spark: SparkSession, in: DataFrame): Unit =\n    in.write\n        .format("parquet")\n        .mode("overwrite")\n        .save("dbfs:/data/test_output.parquet")\n}\n')))),(0,n.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,n.kt)("div",{parentName:"div",className:"admonition-heading"},(0,n.kt)("h5",{parentName:"div"},(0,n.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,n.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,n.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,n.kt)("div",{parentName:"div",className:"admonition-content"},(0,n.kt)("p",{parentName:"div"},"To know more about tweaking Parquet related properties in Spark config ",(0,n.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/sql-data-sources-parquet.html"},(0,n.kt)("strong",{parentName:"a"},"click here")),"."))))}k.isMDXComponent=!0}}]);