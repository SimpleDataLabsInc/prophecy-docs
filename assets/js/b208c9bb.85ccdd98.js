"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[85619],{57195:e=>{e.exports=JSON.parse('{"tag":{"label":"gems","permalink":"/tags/gems","allTagsPath":"/tags","count":91,"items":[{"id":"analysts/development/gems/transform/aggregate","title":"Aggregate","description":"Group and pivot your data","permalink":"/analysts/aggregate"},{"id":"Spark/gems/transform/aggregate","title":"Aggregate","description":"Group data and apply aggregation methods or pivot operations","permalink":"/engineers/aggregate"},{"id":"Spark/gems/source-target/file/avro","title":"Avro","description":"Parameters and properties to read from and write to Avro files","permalink":"/engineers/avro"},{"id":"Spark/gems/source-target/warehouse/bigquery","title":"BigQuery","description":"Parameters and properties to read from and write to the BigQuery warehouse","permalink":"/engineers/bigquery"},{"id":"Spark/gems/transform/bulk-column-expressions","title":"BulkColumnExpressions","description":"Change the data type of multiple columns at once","permalink":"/engineers/bulk-column-expressions"},{"id":"Spark/gems/transform/bulk-column-rename","title":"BulkColumnRename","description":"Rename multiple columns in your dataset in a systematic way","permalink":"/engineers/bulk-column-rename"},{"id":"Spark/gems/transform/column-parser","title":"ColumnParser","description":"Parse XML or JSON inside a table","permalink":"/engineers/column-parser"},{"id":"Spark/gems/join-split/compare-columns","title":"CompareColumns","description":"Compare columns between two dataframes","permalink":"/engineers/compare-columns"},{"id":"Spark/gems/source-target/warehouse/cosmos","title":"CosmosDB","description":"Parameters and properties to read from and write to the CosmosDB warehouse","permalink":"/engineers/cosmosdb"},{"id":"analysts/development/gems/spatial/create-point","title":"CreatePoint","description":"Create geographic points with longitude and latitude coordinates","permalink":"/analysts/create-point"},{"id":"Spark/gems/source-target/file/csv","title":"CSV","description":"Parameters and properties to read from and write to CSV files","permalink":"/engineers/csv"},{"id":"analysts/development/gems/prepare/data-cleansing","title":"DataCleansing","description":"Standardize data formats","permalink":"/analysts/data-cleansing"},{"id":"Spark/gems/transform/data-cleansing","title":"DataCleansing","description":"Standardize data formats and address missing or null values in the data","permalink":"/engineers/data-cleansing"},{"id":"Spark/gems/transform/data-quality-check","title":"DataQualityCheck","description":"Ensure your data adhere to predefined constraints","permalink":"/engineers/data-quality-check"},{"id":"Spark/gems/source-target/warehouse/db2","title":"DB2","description":"DB2","permalink":"/engineers/db2"},{"id":"analysts/development/gems/prepare/deduplicate","title":"Deduplicate","description":"Remove duplicates from your data","permalink":"/analysts/deduplicate"},{"id":"Spark/gems/transform/deduplicate","title":"Deduplicate","description":"Remove rows with duplicate values of specified columns","permalink":"/engineers/deduplicate"},{"id":"Spark/gems/source-target/file/delta","title":"Delta","description":"Parameters and properties to read from and write to Delta files","permalink":"/engineers/delta"},{"id":"Spark/gems/source-target/catalog-table/delta","title":"Delta Table","description":"Read from or write to tables managed by a Delta table metastore","permalink":"/engineers/delta-table"},{"id":"Spark/gems/custom/directory","title":"Directory","description":"Return a listing of all the files in a specified directory","permalink":"/engineers/directory"},{"id":"analysts/development/gems/spatial/distance","title":"Distance","description":"Calculate the distance between two points","permalink":"/analysts/distance"},{"id":"Spark/gems/transform/dynamic-replace","title":"DynamicReplace","description":"Dynamically generate values depending on certain conditions","permalink":"/engineers/dynamic-replace"},{"id":"analysts/development/gems/transform/dynamic-select","title":"DynamicSelect","description":"Dynamically filter columns of your dataset based on a set of conditions","permalink":"/analysts/dynamic-select"},{"id":"Spark/gems/transform/dynamic-select","title":"DynamicSelect","description":"Dynamically filter columns of your dataset based on a set of conditions","permalink":"/engineers/dynamic-select"},{"id":"analysts/development/gems/report/email","title":"Email","description":"Send your pipeline output tables to others via email","permalink":"/analysts/email"},{"id":"Spark/gems/custom/email","title":"Email","description":"Send emails via your Spark pipeline","permalink":"/engineers/email"},{"id":"Spark/gems/custom/email-data","title":"EmailData","description":"Send data from your Spark pipeline to others by email","permalink":"/engineers/email-data"},{"id":"analysts/development/gems/prepare/filter","title":"Filter","description":"Filter the data","permalink":"/analysts/filter"},{"id":"Spark/gems/transform/filter","title":"Filter","description":"Filter your data based on a custom filter condition","permalink":"/engineers/filter"},{"id":"Spark/gems/source-target/file/fixed-format","title":"Fixed Format","description":"Parameters and properties to read from and write to Fixed Format files","permalink":"/engineers/fixed-format"},{"id":"analysts/development/gems/prepare/flatten-schema","title":"FlattenSchema","description":"Flatten nested columns","permalink":"/analysts/flatten-schema"},{"id":"Spark/gems/transform/flatten-schema","title":"FlattenSchema","description":"Flatten nested data","permalink":"/engineers/flatten-schema"},{"id":"analysts/development/functions/functions","title":"Functions","description":"Build functions with SQL macros to be used in gem expressions","permalink":"/analysts/functions"},{"id":"analysts/development/gems/transform/fuzzy-match","title":"FuzzyMatch","description":"Match records that are not exactly identical","permalink":"/analysts/fuzzy-match"},{"id":"Spark/gems/transform/fuzzy-match","title":"FuzzyMatch","description":"Identify non-identical duplicates in your data","permalink":"/engineers/fuzzy-match"},{"id":"analysts/development/gems/gems","title":"Gems","description":"Power your pipelines with gems","permalink":"/analysts/gems"},{"id":"getting-started/concepts/gems","title":"Gems","description":"Transform your data with Prophecy gems","permalink":"/gems"},{"id":"Spark/gems/source-target/catalog-table/hive","title":"Hive Table","description":"Read from or write to tables managed by a Hive metastore","permalink":"/engineers/hive-table"},{"id":"Spark/gems/source-target/catalog-table/iceberg","title":"Iceberg","description":"Read from or write to tables managed by Iceberg","permalink":"/engineers/iceberg"},{"id":"Spark/gems/source-target/warehouse/jdbc","title":"JDBC","description":"Parameters and properties to read from and write to the JDBC warehouse","permalink":"/engineers/jdbc"},{"id":"analysts/development/gems/join-split/join","title":"Join","description":"Join two or more datasets","permalink":"/analysts/join"},{"id":"Spark/gems/join-split/join","title":"Join","description":"Join one or more DataFrames on conditions","permalink":"/engineers/join"},{"id":"Spark/gems/source-target/file/json","title":"JSON","description":"Parameters and properties to read from and write to JSON files","permalink":"/engineers/json"},{"id":"analysts/development/gems/parse/json-parse","title":"JSONParse","description":"Parse JSON inside a table","permalink":"/analysts/json-parse"},{"id":"Spark/gems/source-target/file/kafka","title":"Kafka","description":"Parameters and properties to read from and write to Kafka files","permalink":"/engineers/kafka"},{"id":"analysts/development/gems/prepare/limit","title":"Limit","description":"Limit the number of columns processed","permalink":"/analysts/limit"},{"id":"Spark/gems/transform/limit","title":"Limit","description":"Limit the number of rows","permalink":"/engineers/limit"},{"id":"Spark/gems/source-target/lookup","title":"Lookup","description":"Lookup","permalink":"/engineers/lookup"},{"id":"analysts/development/gems/custom/macro","title":"Macro","description":"Use dbt macros in your pipelines","permalink":"/analysts/macro"},{"id":"Spark/gems/source-target/warehouse/mongodb","title":"MongoDB","description":"Parameters and properties to read from and write to the MongoDB warehouse.","permalink":"/engineers/mongodb"},{"id":"analysts/development/gems/prepare/multi-column-edit","title":"MultiColumnEdit","description":"Change the data type of multiple columns at once","permalink":"/analysts/multi-column-edit"},{"id":"analysts/development/gems/prepare/multi-column-rename","title":"MultiColumnRename","description":"Rename multiple columns in your dataset in a systematic way","permalink":"/analysts/multi-column-rename"},{"id":"Spark/gems/source-target/warehouse/oracle","title":"Oracle","description":"Oracle","permalink":"/engineers/oracle"},{"id":"Spark/gems/source-target/file/orc","title":"ORC","description":"Parameters and properties to read from and write to ORC files","permalink":"/engineers/orc"},{"id":"analysts/development/gems/prepare/order-by","title":"OrderBy","description":"Sort the data","permalink":"/analysts/order-by"},{"id":"Spark/gems/transform/order-by","title":"OrderBy","description":"Sort your data based on one or more columns","permalink":"/engineers/order-by"},{"id":"Spark/gems/source-target/file/parquet","title":"Parquet","description":"Parameters and properties to read from and write to Parquet files","permalink":"/engineers/parquet"},{"id":"Spark/gems/source-target/warehouse/redshift","title":"Redshift","description":"Parameters and properties to read from and write to the Redshift warehouse.","permalink":"/engineers/redshift"},{"id":"analysts/development/gems/prepare/reformat","title":"Reformat","description":"Use expressions to reformat column names and values","permalink":"/analysts/reformat"},{"id":"Spark/gems/transform/reformat","title":"Reformat","description":"Select one or more columns or values using expressions and functions","permalink":"/engineers/reformat"},{"id":"Spark/gems/join-split/Repartition","title":"Repartition","description":"Repartition or coalesce a DataFrame","permalink":"/engineers/repartition"},{"id":"analysts/development/gems/custom/rest-api","title":"RestAPI","description":"Call APIs from your pipeline.","permalink":"/analysts/rest-api"},{"id":"Spark/gems/custom/rest-api-enrich","title":"RestAPIEnrich","description":"Enrich DataFrame with content from rest API response based on configuration","permalink":"/engineers/rest-api-enrich"},{"id":"Spark/gems/join-split/row-distributor","title":"RowDistributor","description":"Create multiple DataFrames based on filter conditions","permalink":"/engineers/row-distributor"},{"id":"Spark/gems/source-target/web-apps/salesforce","title":"Salesforce","description":"Salesforce","permalink":"/engineers/salesforce"},{"id":"Spark/gems/transform/sample-rows","title":"SampleRows","description":"Sample records by choosing a specific number or percentage of records","permalink":"/engineers/sample-rows"},{"id":"Spark/gems/transform/schema-transform","title":"SchemaTransform","description":"Add, Edit, Rename or Drop Columns","permalink":"/engineers/schema-transform"},{"id":"analysts/development/gems/custom/script","title":"Script","description":"Leverage a Python script in your pipeline","permalink":"/analysts/development/gems/custom/script"},{"id":"Spark/gems/source-target/file/seed","title":"Seed","description":"Parameters and properties to read from Seed files","permalink":"/engineers/seed"},{"id":"Spark/gems/transform/set-operation","title":"SetOperation","description":"Union, Intersect and Difference","permalink":"/engineers/set-operation"},{"id":"Spark/gems/source-target/web-apps/smartsheet","title":"Smartsheet","description":"Use data from Smartsheet in your Spark pipeline","permalink":"/engineers/smartsheet"},{"id":"Spark/gems/source-target/warehouse/snowflake","title":"Snowflake","description":"Parameters and properties to read from and write to the Snowflake warehouse.","permalink":"/engineers/snowflake"},{"id":"Spark/gems/source-target/source-target","title":"Source And Target","description":"Set of gems related to reading and writing data","permalink":"/engineers/source-target"},{"id":"Spark/spark-streaming/streaming","title":"Spark Structured Streaming","description":"Prophecy Streaming Gems","permalink":"/engineers/spark-streaming"},{"id":"data-modeling/gems/sql-gems","title":"SQL Gems","description":"Gems are data seeds, sources, transformations, and targets","permalink":"/engineers/data-modeling-gems"},{"id":"analysts/development/gems/custom/sql-statement","title":"SQL statement","description":"Use a custom SQL statement","permalink":"/analysts/sql-statement"},{"id":"Spark/gems/custom/sql-statement","title":"SQLStatement","description":"Create DataFrames based on custom SQL queries","permalink":"/engineers/sql-statement"},{"id":"Spark/gems/custom/tableau","title":"Tableau","description":"Send data from your Spark pipeline to Tableau","permalink":"/engineers/tableau"},{"id":"analysts/development/gems/report/tableau","title":"TableauWrite","description":"Send data to automatically update your Tableau dashboards","permalink":"/analysts/tableau"},{"id":"Spark/gems/source-target/warehouse/teradata","title":"Teradata","description":"Teradata","permalink":"/engineers/teradata"},{"id":"Spark/gems/source-target/file/text","title":"Text","description":"Parameters and properties to read from and write to Text file","permalink":"/engineers/text"},{"id":"analysts/development/gems/parse/text-to-column","title":"TextToColumns","description":"Convert text into a column in your table","permalink":"/analysts/text-to-column"},{"id":"analysts/development/gems/transform/transpose","title":"Transpose","description":"Convert your table from wide to long format","permalink":"/analysts/transpose"},{"id":"Spark/gems/transform/unpivot","title":"Unpivot","description":"Use the Unpivot gem to transform your data from a wide format to a long format","permalink":"/engineers/unpivot"},{"id":"Spark/gems/source-target/file/upload-file","title":"Upload files","description":"Learn how to upload files to your Spark pipeline","permalink":"/engineers/upload-file"},{"id":"Spark/gems/subgraph/while-iterator","title":"WhileIterator","description":"Recursively processes rows","permalink":"/engineers/while-iterator"},{"id":"analysts/development/gems/transform/window","title":"WindowFunction","description":"Create moving aggregations and transformation","permalink":"/analysts/window"},{"id":"Spark/gems/transform/window-function","title":"WindowFunction","description":"Aggregate and transform Windowed data","permalink":"/engineers/window-function"},{"id":"Spark/gems/source-target/file/xlsx","title":"XLSX (Excel)","description":"Parameters and properties to read from and write too XLSX (Excel) files","permalink":"/engineers/xlsx"},{"id":"Spark/gems/source-target/file/xml","title":"XML","description":"Parameters and properties to read from and write to XML files","permalink":"/engineers/xml"},{"id":"analysts/development/gems/parse/xml-parse","title":"XMLParse","description":"Parse XML inside a table","permalink":"/analysts/xml-parse"}],"unlisted":false}}')}}]);