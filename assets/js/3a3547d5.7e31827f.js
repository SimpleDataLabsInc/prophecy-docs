"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[96665],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var i=t(96540);const o={},s=i.createContext(o);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},69279:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/dev-qa-prod-be4c5dab33d67936196d5f3660e0e263.png"},81660:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"ci-cd/reliable-ci-cd","title":"CI/CD for Spark pipelines","description":"Continuous integration and continuous delivery in Prophecy","source":"@site/docs/ci-cd/reliable-ci-cd.md","sourceDirName":"ci-cd","slug":"/engineers/ci-cd","permalink":"/engineers/ci-cd","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"cicd","permalink":"/tags/cicd"},{"inline":true,"label":"deployment","permalink":"/tags/deployment"},{"inline":true,"label":"devops","permalink":"/tags/devops"},{"inline":true,"label":"qa","permalink":"/tags/qa"},{"inline":true,"label":"testing","permalink":"/tags/testing"}],"version":"current","frontMatter":{"title":"CI/CD for Spark pipelines","id":"reliable-ci-cd","slug":"/engineers/ci-cd","description":"Continuous integration and continuous delivery in Prophecy","tags":["cicd","deployment","devops","qa","testing"]},"sidebar":"mySidebar","previous":{"title":"Lineage extractor","permalink":"/engineers/lineage-extractor"},"next":{"title":"Git","permalink":"/engineers/git"}}');var o=t(74848),s=t(28453);const r={title:"CI/CD for Spark pipelines",id:"reliable-ci-cd",slug:"/engineers/ci-cd",description:"Continuous integration and continuous delivery in Prophecy",tags:["cicd","deployment","devops","qa","testing"]},l=void 0,a={},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Environment setup",id:"environment-setup",level:2},{value:"Pipeline development workflow",id:"pipeline-development-workflow",level:2},{value:"Step 1: Create a project",id:"step-1-create-a-project",level:3},{value:"Step 2: Develop and test",id:"step-2-develop-and-test",level:3},{value:"Step 3: Deploy to QA",id:"step-3-deploy-to-qa",level:3},{value:"Step 4: Deploy to production",id:"step-4-deploy-to-production",level:3},{value:"Project deployment options",id:"project-deployment-options",level:2},{value:"Option 1: Prophecy-native CI/CD",id:"option-1-prophecy-native-cicd",level:3},{value:"Option 2: External CI/CD with PBT",id:"option-2-external-cicd-with-pbt",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.p,{children:["Learn how to set up continuous integration and deployment (",(0,o.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/CI/CD",children:"CI/CD"}),") for your Prophecy data pipelines using environment separation and testing. This page outlines how to:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Configure multi-environment deployments"}),"\n",(0,o.jsx)(n.li,{children:"Set up testing and validation"}),"\n",(0,o.jsx)(n.li,{children:"Deploy pipelines using Prophecy's built-in tools or external CI/CD systems"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.p,{children:"To set up CI/CD successfully in Prophecy, ensure that you have:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Access to target execution environments (Databricks workspaces, for example)"}),"\n",(0,o.jsx)(n.li,{children:"Empty Git repositories configured for your projects"}),"\n",(0,o.jsx)(n.li,{children:"Understanding of your data pipeline requirements and SLAs"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"environment-setup",children:"Environment setup"}),"\n",(0,o.jsx)(n.p,{children:"We recommend setting up separate environments (fabrics) for each stage of deployment. The table below illustrates one example of a multi-fabric setup."}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Fabric"}),(0,o.jsx)(n.th,{children:"Purpose"}),(0,o.jsx)(n.th,{children:"Data"}),(0,o.jsx)(n.th,{children:"Access"}),(0,o.jsx)(n.th,{children:"Cluster Size"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Development"}),(0,o.jsx)(n.td,{children:"Feature development and initial testing"}),(0,o.jsx)(n.td,{children:"Synthetic or anonymized datasets"}),(0,o.jsx)(n.td,{children:"Dev team"}),(0,o.jsx)(n.td,{children:"Small"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"QA/Staging"}),(0,o.jsx)(n.td,{children:"Testing and validation"}),(0,o.jsx)(n.td,{children:"Production-like data samples"}),(0,o.jsx)(n.td,{children:"QA team"}),(0,o.jsx)(n.td,{children:"Medium"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Production"}),(0,o.jsx)(n.td,{children:"Live data processing"}),(0,o.jsx)(n.td,{children:"Real production data"}),(0,o.jsx)(n.td,{children:"Prod team"}),(0,o.jsx)(n.td,{children:"Large"})]})]})]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Data pipeline",src:t(69279).A+"",width:"3000",height:"1604"})}),"\n",(0,o.jsx)(n.admonition,{title:"See Also",type:"info",children:(0,o.jsxs)(n.p,{children:["To learn more about the relationship between fabrics, projects, and teams, visit ",(0,o.jsx)(n.a,{href:"/administration/team-based-access",children:"Team-based Access"}),"."]})}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"While you are not required to have multiple execution environments in Prophecy, it is best practice to keep development and production data and access separate."})}),"\n",(0,o.jsx)(n.h2,{id:"pipeline-development-workflow",children:"Pipeline development workflow"}),"\n",(0,o.jsx)(n.p,{children:"Here is an example pipeline development workflow for teams that leverage multiple environments."}),"\n",(0,o.jsx)(n.h3,{id:"step-1-create-a-project",children:"Step 1: Create a project"}),"\n",(0,o.jsx)(n.p,{children:"Start by creating a new project in Prophecy. The project should have its own dedicated Git repository, which helps maintain a clean version history and enables collaboration across teams. The project should be assigned to a team that includes every user who will need to access this project throughout its lifecycle. This is possible because the project team can differ from the fabric team, which should be more restrictive."}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"While you can technically use an empty directory to host your Prophecy project instead, this is not recommended."})}),"\n",(0,o.jsx)(n.h3,{id:"step-2-develop-and-test",children:"Step 2: Develop and test"}),"\n",(0,o.jsxs)(n.p,{children:["Develop pipelines in the development environment using the ",(0,o.jsx)(n.code,{children:"dev"})," branch. This stage involves building pipelines and configuring pipeline parameters to handle different runtime scenarios or environment-specific values. Execute pipelines interactively during development and inspect runtime logs to debug and validate pipeline behavior. During development, you can also create jobs that will automate pipeline execution after deployment."]}),"\n",(0,o.jsx)(n.h3,{id:"step-3-deploy-to-qa",children:"Step 3: Deploy to QA"}),"\n",(0,o.jsxs)(n.p,{children:["Once development and initial validation are complete, the QA team can begin validating the pipelines by running them interactively in the QA environment. Then, changes to the project can be merged to the ",(0,o.jsx)(n.code,{children:"main"})," branch and deployed in the QA environment to test if scheduled pipelines run as expected. This stage ensures that your pipelines and jobs function as expected in a controlled, production-like setting before they are released to live systems."]}),"\n",(0,o.jsx)(n.h3,{id:"step-4-deploy-to-production",children:"Step 4: Deploy to production"}),"\n",(0,o.jsx)(n.p,{children:"After the QA team has validated the project, the project can be deployed to production. Typically, a small, designated platform team is responsible for this step. The project is deployed to the production fabric, where jobs operate on real production data and run at scale. Jobs in production should ideally execute using a service principal rather than a user identity, since it is an unattended operation."}),"\n",(0,o.jsx)(n.h2,{id:"project-deployment-options",children:"Project deployment options"}),"\n",(0,o.jsx)(n.p,{children:"You can deploy Prophecy projects using either the built-in Git-based workflow or through an external CI/CD system using the Prophecy Build Tool (PBT). Both approaches support multi-environment pipelines and can integrate automated testing into your release process."}),"\n",(0,o.jsx)(n.h3,{id:"option-1-prophecy-native-cicd",children:"Option 1: Prophecy-native CI/CD"}),"\n",(0,o.jsx)(n.p,{children:"Prophecy includes a native Git-based CI/CD workflow integrated directly into the project editor. This allows you to manage the entire lifecycle without leaving the Prophecy interface. In Prophecy's Git-based workflow, a release marks a specific version of your project by creating a Git tag, while deployment builds and pushes that version to your chosen environment. These steps usually run together but can also be executed independently. As part of the release process, Prophecy automatically builds the code, runs unit tests, and packages everything needed (such as JARs or wheels) to deploy pipelines and jobs."}),"\n",(0,o.jsx)(n.admonition,{title:"See Also",type:"info",children:(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/engineers/git",children:"Git"})," to learn more about the Git workflow"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/engineers/unit-tests",children:"Unit tests"})," for validating pipeline functionality"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/engineers/deployment",children:"Deployment"})," to deep dive into the phases of project deployment"]}),"\n"]})}),"\n",(0,o.jsx)(n.h3,{id:"option-2-external-cicd-with-pbt",children:"Option 2: External CI/CD with PBT"}),"\n",(0,o.jsxs)(n.p,{children:["If your organization already uses an external CI/CD system, you can integrate Prophecy projects using the Prophecy Build Tool (PBT), a command-line interface designed for automation. PBT works with systems like ",(0,o.jsx)(n.a,{href:"/engineers/github-actions-prophecy-build-tool",children:"GitHub Actions"})," and ",(0,o.jsx)(n.a,{href:"/engineers/jenkins-prophecy-build-tool",children:"Jenkins"})," to build and deploy Prophecy projects from a Git repository."]}),"\n",(0,o.jsxs)(n.p,{children:["This approach supports the same multi-environment model as native CI/CD. Use the ",(0,o.jsx)(n.code,{children:"--fabric-ids"})," flag in your CI/CD configuration to target specific fabrics during deployment."]}),"\n",(0,o.jsx)(n.p,{children:"To use PBT in your CI/CD pipeline:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Install the Prophecy Build Tool."}),"\n",(0,o.jsx)(n.li,{children:"Configure secrets to securely store credentials and environment connection details."}),"\n",(0,o.jsx)(n.li,{children:"Set up your GitHub Actions or Jenkins workflow to include build and deploy steps using PBT."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["For detailed instructions and examples, see ",(0,o.jsx)(n.a,{href:"/engineers/prophecy-build-tool",children:"Prophecy Build Tool (PBT)"}),"."]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);